abstract	author	category	desc	level	title	weekday	start_dt	end_dt
	Julia Evans	Opening Statements	Julia Evans is a programmer & data scientist based in Montréal, Quebec. She loves coding, math, playing with datasets, teaching programming, open source communities, and late night discussions on how to dismantle oppression. She co-organizes PyLadies Montréal and Montréal All-Girl Hack Night.		Opening Statements	Friday	2015-04-10 09:00:00	2015-04-10 09:30:00
	Catherine Bracy	Keynote	"Catherine oversees Code for America’s civic engagement portfolio, including the Brigade program. She also founded and runs Code for All, Code for America’s international partnership program.

Until November 2012, she was Director of Obama for America’s technology field office in San Francisco, the first of its kind in American political history. She was responsible for organizing technologists to volunteer their skills to the campaign’s technology and digital efforts.

Prior to joining the campaign, she ran the Knight Foundation’s 2011 News Challenge and before that was the administrative director at Harvard’s Berkman Center for Internet & Society. She is on the board of directors at the Citizen Engagement Lab and the Public Laboratory."		Director, Code for America	Friday	2015-04-10 09:30:00	2015-04-10 10:10:00
	Guido van Rossum	Keynote	"Guido van Rossum is the author of the Python programming language. He continues to serve as the ""Benevolent Dictator For Life"" (BDFL), meaning that he continues to oversee the Python development process, making decisions where necessary. He is currently employed by Dropbox."		Python's Creator	Saturday	2015-04-11 09:00:00	2015-04-11 09:40:00
	Gabriella Coleman	Keynote	"Gabriella (Biella) Coleman holds the Wolfe Chair in Scientific and Technological Literacy at McGill University. Trained as a cultural anthropologist, she researches, writes, and teaches on computer hackers and digital activism and is the author of two books.

Her first book, Coding Freedom: The Ethics and Aesthetics of Hacking, was published with Princeton University Press in 2013 and her most recent book, Hacker, Hoaxer, Whistleblower, Spy: The Many Faces of Anonymous, published by Verso, has been named to Kirkus Reviews' Best Books of 2014.

You can learn more about her work on her website: http://gabriellacoleman.org/."		Author & Professor	Saturday	2015-04-11 09:40:00	2015-04-11 10:20:00
	Van Lindberg	Keynote	Van Lindberg is Vice President of Intellectual Property at Rackspace. He is trained as a computer engineer and lawyer, but what he does best is “translate” to help businesses, techies and attorneys understand each other. Van likes working with both computer code and legal code. For the past several years, he has been using natural language processing and graph theory to help him digest and map the U.S. Patent Database. Van is currently chairman of the board of the Python Software Foundation, as well as the author of Intellectual Property and Open Source.		PSF Chair	Sunday	2015-04-12 09:00:00	2015-04-12 09:20:00
	Jacob Kaplan-Moss	Keynote	Jacob Kaplan-Moss is the co-creator of Django and the founder of the Django Software Foundation. He has over a decade of experience as a web, open source, and Python developer. He is currently Director of Security at Heroku.		Django's Co-creator	Sunday	2015-04-12 09:20:00	2015-04-12 10:00:00
	Gary Bernhardt	Keynote	Gary Bernhardt is a creator and destroyer of software compelled to understand both sides of heated software debates: Vim and Emacs; Python and Ruby; Git and Mercurial. He runs  Destroy All Software, which publishes advanced screencasts for serious developers covering Unix, OO design, TDD, and dynamic languages.		Closing Keynote	Sunday	2015-04-12 15:10:00	2015-04-12 15:50:00
Without virtual environments, your installed libraries can become a mess of spaghetti dependencies. To illustrate this point, we’ll show a couple examples of what can go wrong if you don’t use a virtual environment. Next, we’ll briefly talk about what virtual environments are and how they work. Lastly, we’ll set up sample projects using virtualenv and show you how easy it is to keep your installed libraries isolated for each project.	Renee Chu,Matt Makai	Python Core (language, stdlib, etc.)	Even though it’s possible to program without using virtual environments, you can shoot yourself in the foot without them. This talk will start with an illustration of how not using virtual environments can mess you up as a programmer, and will walk you through a simple way to get started with good habits using virtualenv.	Novice	Don't Make Us Say We Told You So: virtualenv for New Pythonistas	Friday	2015-04-10 16:30:00	2015-04-10 17:00:00
overview This tutorial aims to teach participants how to use standard Python tools and Plotly to create stunning data visualizations which can be shared and leveraged as a platform for collaboration.  takeaways After completion of the tutorial, students will be able to use their data to create matplotlib and Plotly figures from a Python script. They will be able to convert matplotlib figures into interactive graphs and subsequently share them on the web. Beginner Python programmers will get a feel for using the language and all will learn how to make beautiful data visualizations in the browser. requirements To participate in the entire tutorial, students will need to install Python and the following packages: numpy, matplotlib, ipython[notebook], and plotly. Students will also need to create an account here https://plot.ly. They may want to follow the getting started instructions here https://plot.ly/python/getting-started. If students run into any difficulties getting their environments setup for this tutorial they may contact the presenters directly at: andrew@plot.ly, etienne@plot.ly, and marianne@plot.ly. format The format of the tutorial is that of an interactive classroom.  Deriving motivation from real-world data visualization needs in science and journalism, we begin by showing how to get from data to basic, informative visualizations quickly and easily.  Students will then be introduced to different ways of improving and customizing their graphs.  We will also show how to edit existing graphs and instructors will engage students to help them explore on their own.  We will put forward an exploratory approach and address reproducibility, which is made possible by a seamless workflow in the Python world (use of Python scripts, the IPython Notebook, Plotly’s Python package).	Andrew Seier,Étienne Tétreault-Pinard,Marianne Corvellec	Python Libraries	From Python basics to NYT-quality graphics, we walk through workflows to make beautiful, shareable data visualizations. We’ll also explore 3D plotting in the browser, cross-language collaboration, and matplotlib figure conversion. By using Python’s scientific stack and an IPython notebook--attendees may follow along. For data analysts, data journalists, and anyone who likes plots.	Novice	Making Beautiful Graphs in Python and Sharing Them	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Distributed systems are a fairly advanced field of computer science. As systems increase in scale, it's becoming increasingly more important. Furthermore, you could argue that our individual nodes themselves are increasingly becoming like distributed systems. Unfortunately, the field has some similarities to cryptography and information security. They're considered very difficult fields to be left primarily to experts; there's a plethora of papers available on subjects both theoretical and applied, and yet, we seem to do a poor job educating people. Most of us are left to self-educate, but the material is poorly organized for that purpose. This talk intends to give a very brief introduction to distributed systems theory and practice, a kind of selected reading list, rules of thumb, and a healthy dose of existential fear.	lvh	Best Practices & Patterns	A very brief introduction to the theory and practice of distributed systems.	Intermediate	Distributed Systems 101	Friday	2015-04-10 13:40:00	2015-04-10 14:25:00
Are you interested in learning how to orchestrate and configure servers? This tutorial will cover Ansible, a popular orchestration and configuration management tool written in Python. We'll cover:  Writing Ansible playbooks for tasks such as installing and configuration software, and piecing together an application deployment. Writing reusable, exportable Ansible roles. Writing inventory and lookup plugins to extend Ansible's core functionality.  Finally, we'll conclude by deploying an actual application.	Luke Sneeringer	Systems Administration	Interested in Ansible, or in server orchestration and configuration generally? This tutorial will teach the basics -- and a few of the not-so-basics -- of orchestrating machines with Ansible.	Intermediate	Ansible 101	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Software engineers are never done learning as our field is always changing. We are always beginners at some things and experts at others. Along the way from beginner to expert we ask a lot of questions, but it can be intimidating to ask for help. There are some common mistakes experts inadvertently make that make people feel self-conscious and stupid for getting help, when asking for help is actually the best thing they could do! This talk will be split into two halves: giving and then getting technical help. It will give you concrete tools and tips for asking for help, and give you a checklist to see if you’re currently making any of these common mistakes when it’s your turn to answer questions. Improve your communication skills, get along better with your coworkers and colleagues, and learn faster than ever.	Sasha Laundy	Community	Software engineers are never done learning since our field is always changing. We are always beginners at some things and experts at others. Along the way from beginner to expert we have to ask a lot of questions, but it can be hard to get help. This talk gives concrete tools to help you ask with confidence, and highlights common expert mistakes that inadvertently make people feel foolish.	Novice	Your Brain's API: Giving and Getting Technical Help	Saturday	2015-04-11 16:30:00	2015-04-11 17:00:00
PBS digital streams many videos online and this is not a trivial task.  Once you build an online video streaming system, you have touched many elements that you can control.  The remaining elements are things you cannot control: ISP bandwidth, user computers, Net Neutrality, and solar flares.   Thus, PBS has invested in creating a basic framework for collecting video streaming data, processing it, and visualizing it.  This talk reviews the technologies involved including, but not limited to:  Map Reduce Large database queries Lightweight data collection servers Video player instrumentation Data visualization tools  We created the framework to be open and modular so that various technologies can be slotted in to be customized to various environments.	Mike Howsden	Python Libraries	It is extremely important to PBS that digital viewers have an awesome experience when viewing online videos.  In this talk, we explain how PBS built a system to collect, analyze, and measure who's getting a good experience -- and who's not.	Intermediate	Zen of Quality - How PBS measures QoS for digital viewers	Sunday	2015-04-12 14:30:00	2015-04-12 15:00:00
Follow along as we package and deploy a simple Python-based webapp on a CoreOS cluster... and then try to destroy it. Discover how Fleet, Docker, and etcd keep the app running, even as we carelessly destroy VMs in the cluster.	Dan Callahan	Systems Administration	CoreOS is a new Linux distribution that makes it easy to deploy applications on dynamically scaled clusters of computers, and which has recently been embraced by infrastructure providers like DigitalOcean, Rackspace, and Google Compute Engine. Come learn how to package and deploy a Python application on this new, Docker-based platform.	Experienced	Fire your supervisord: running Python apps on CoreOS	Friday	2015-04-10 16:15:00	2015-04-10 17:00:00
Biology is entering an exciting time, where human genomes are fairly inexpensive to sequence, computer algorithms for analyzing the data are becoming more sophisticated, and databases for understanding genomic function are growing in size.  Suppose you get your genome sequenced — what’s in there, how would you interpret it, what software might you use, and what kind of limits are there to the information you can pull out of your genome sequence? All of the analysis will be done in an open github repo with the presentation built on top of an IPython Notebook, of course.  Also, many of the basic mapping and querying algorithms involved in genomic analysis are simple enough that I will provide Python pseucodode of them, as well as provide references to further discussions of the algorithms and databases.	Titus Brown	Science	We’ve entered the era of the $1000 human genome, and soon it will be straightforward to get your own genome sequenced by a commercial company.  But what does the data mean? What information can you get out of your genomic sequence? And what are the barriers to deeper analysis?  What kinds of algorithms and databases are used in genomic analysis? All this, and more, will be revealed in this talk.	Intermediate	How to interpret your own genome using (mostly) Python.	Friday	2015-04-10 15:15:00	2015-04-10 16:00:00
While everyone agrees that usability testing should be an important part of your development process, not everyone has enough money laying around to pay for a dedicated team or consultants. In this talk, Katie will review a number of inexpensive options that can help any team deliver a usable product.  The purpose of this talk is not to demeen the field of usability experts (if you have the money, you should hire some!), but to help those who are working on a shoe-string budget make better websites. Not every team can afford weeks (and sometimes months) of focused user surveys and specialized observation, but most can afford a pack of index cards and a few pieces of inexpensive software. The audience will walk away not only with an idea of why they might want to do usability testing, but also how they can run a few small-scale studies themselves. These will help them pick the right design, organize their site in a logical manner, and tweak their application as time goes on and their needs change.	Katie Cunningham	Best Practices & Patterns	While everyone agrees that usability testing should be an important part of your development process, not everyone has enough money laying around to pay for a dedicated team or consultants. In this talk, Katie will review a number of inexpensive options that can help any team deliver a usable product.	Novice	Usability Testing on the Cheap	Saturday	2015-04-11 11:30:00	2015-04-11 12:00:00
You may have learned Python's advanced syntax for functions (like *args and **kwargs), but the best time to use it may still not be obvious. The goal of this talk is to provide clear advice on how and when to use the Python language features that affect functions (and methods). This talk will present a number of concrete suggestions for how to use functions effectively. With each suggestion I'll use code examples to demonstrate why this is the best choice and why other approaches aren't a good idea.	Brett Slatkin	Best Practices & Patterns	Functions improve readability, encourage reuse, and facilitate refactoring. Python has many unique features that make functions significantly more powerful. This talk will show you the best ways to use functions in Python: when *args is helpful and when it'll crash your programs; how to use generators for arguments and return values; the value of keyword vs. keyword-only arguments; and more!	Novice	How to Be More Effective with Functions	Friday	2015-04-10 10:50:00	2015-04-10 11:20:00
"Git is a powerful tool for describing and maintaining the history of a project, but most people never get beyond the basics. By giving you the ability to rewrite history (with the safety of never truly losing information), git allows you to craft a history that is more true to the intent of your changes, rather than one filled with countless ""oops"" and ""fixed typo"" commits. Of course, with great power comes great responsibility, and it is important to wield your time-travelling powers with restraint. In this talk, you'll learn how to clean up your history without confusing others, as well as how to recover if things go wrong. You'll also learn more about the conceptual model behind git and how to bend it to your will. Once you understand how commits and branches really work, you can compose your git tools to do what you want. Need to insert a commit in the middle of a branch? See who introduced the bug two weeks ago that surfaced in production today? Resolve merge conflicts cleanly? Break a large commits into several smaller ones, or squash several smaller ones together into one? With git, you can do it."	David Baumgold	Best Practices & Patterns	You know clone, commit, push, and pull. Now you're ready for the fun stuff. This talk will give you the advanced knowledge you need to take control of your git repository: rebase, cherry-pick, bisect, blame, squashing, and the reflog. You'll also get a better conceptual understanding of how git works, allowing you to chain these tools together to accomplish whatever task you need.	Novice	Advanced Git	Friday	2015-04-10 14:35:00	2015-04-10 15:05:00
This is a class directed at Python beginners that are interested in learning Web development. In this workshop we are going to build a Web application using Flask, the Python Web micro-framework. The only pre-requisite is that you have a basic knowledge of Python. I will be happy to explain anything you don't understand, but I will assume that you are at least familiar with the language syntax and structure. We will start with the setup of a development environment for Flask in your laptop, and then will work on an application that we will build from scratch in small incremental steps. The main topics that I will cover in this class are Basic Applications, Templates, Web Forms and User Sessions. At the end I will also give you an overview of what you should focus on next. Note that this year my intention is to cover the basic building blocks in very good detail, so this is a class that is ideal for beginners, or those that found my PyCon 2014 tutorial too intimidating. I will welcome questions at all times and also expect all the attendees will have the example application running on their laptops by the end of the class. My hope is that this class will give you a really good taste of what Web development is. By the end of it you will have enough knowledge to build simple Web applications on your own, and if you are interested, you will know what you need to do to continue on your learning path.	Miguel Grinberg	Web Frameworks	"Flask is a web framework for Python based on Werkzeug, Jinja 2 and good intentions. It is considered a micro-framework, but don't get the ""micro"" part fool you; Flask can do everything others can do, many times in a simpler, leaner way. In this tutorial session we will build a web application together. Bring your laptop and your questions!"	Novice	Flask Workshop	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
"Every programming language works similarly to others, and differently than others.  Python is no exception.  Its mechanisms for supporting variables have an underlying simplicity, but preconceptions from other languages can obscure their true behavior. Starting from ""x = 23"", we'll cover how Python names and values work together to provide variables.  Along the way, we'll touch on immutability, containers, reference counting, sharing, copying, the diversity of assignment, dynamic typing, and a tiny bit of chess."	Ned Batchelder	Python Core (language, stdlib, etc.)	The behavior of names and values in Python can be confusing. Like many parts of Python, it has an underlying simplicity that can be hard to discern, especially if you are used to other programming languages. Here I'll explain how it all works, and present some facts and myths along the way.  Call-by-reference? Call-by-value? The answer will be clear!	Novice	Facts and Myths about Python names and values	Saturday	2015-04-11 12:10:00	2015-04-11 12:40:00
Software engineering isn’t just about writing code that correctly executes some task; it’s also about writing code that is easy to use and maintain. A software module’s receptiveness to use by end users or by other software isn’t guaranteed and a particular danger to a module’s usability is inappropriate coupling of the module to its dependencies, clients, and design assumptions. Sometimes bad coupling happens when software is being written in a hurry and its design decisions are being driven by expediency. Sometimes bad coupling is a result of following bad advice. Sometimes bad coupling simply comes from mistakes. Loose coupling between software modules is good coupling. Loose coupling reserves freedom for you in the future as your software’s needs and implementation change. We will share our experiences of dealing with tightly coupled systems written by others and how we have learned to create loosely coupled systems of our own.	Augie Fackler,Nathaniel Manista	Best Practices & Patterns	Great software is made out of cooperating independent modules; unusable, incorrect, and bad software happen when modules don’t (or can’t) work together. What makes modules friendly or hostile? How do abusive relationships between modules happen? How can we write code that creates and maintains healthy connections to other code?	Intermediate	Stop Sucking Me Into Your Drama: A Personal Appeal For Loose Coupling	Friday	2015-04-10 15:15:00	2015-04-10 15:45:00
The problem: async applications must be tested as thoroughly as others, but the typical code flow is broken. “Do something, then assert something” no longer works in the obvious way. After your test code launches an async operation, it needs some way to know when to expect the operation to be complete. Developers inexperienced with async frameworks insert arbitrary sleeps into their tests to wait for the expected outcome, or they write awkward polling loops. The resulting code is unreliable, breaks good testing practices, and is illegible. There has to be a better way. The fetch / wait pattern. Tornado’s “testing” module introduced a pattern that allows async web applications to be easily tested. Your code does some setup and then fetches a URL from your application. Tornado then allows your test to wait cleanly, while the event loop completes processing your request. Finally, your test asserts the post-conditions. Loop management. The event loop must be shut down and recreated between tests to ensure all file descriptors and callbacks are cleared between tests. We’ll see how to manage the loop when testing with Tornado and with asyncio. Coroutine tests. Tornado’s “gen_test” decorator allows you to write tests as generators. We digress to explain asynchronous coroutines in general, then show how they vastly improve async tests’ concision and reliability. Tornado helps you avoid some pitfalls with a few neat tricks, we’ll see how those work. Then we see equivalent examples of testing asyncio applications with coroutines. Don’t sleep. Sometimes a test requires time to pass, but calling time.sleep() in a test is slow, unreliable, and may block the event loop precisely when it needs to be running. The self-tests for asyncio demonstrate some clever patterns to simulate the passage of time while ensuring tests are fast and trustworthy. Conclusion. As async frameworks make their way into the mainstream of Python application programming, we must take the experience we’ve gained with conventional testing and adapt it to a new paradigm. Don’t reinvent the wheel: there are years of wisdom embedded in Tornado’s and asyncio’s testing tools. You can write fast, reliable, and elegant async tests if you use the right techniques.	A. Jesse Jiryu Davis	Testing	Async frameworks like Tornado and asyncio scramble our usual strategies for writing sequential code. This is most problematic when writing tests: how can you validate the outcome when you don’t know when to expect it? This talk introduces you to methods and practices for unittesting async applications.	Intermediate	Eventually Correct: Testing Async Apps	Saturday	2015-04-11 16:30:00	2015-04-11 17:00:00
How does Yelp decide which relevant business or service to show you as an ad within 100 milliseconds of your visit? What are the criteria and metrics by which we measure success of our ad serving system? In this talk, the audience will learn about how Yelp figures out the best ad to show a user during his visit to Yelp: via a 2nd price auction amongst all the matching advertisers. Powering this 2nd price auction is a Machine Learning based system that predicts Click Through Rates (CTR) for all ads and an Auto-Bidding system that determines the optimal bid price for each ad per user request. Yelp's local advertising presents challenges that are unique compared to display, social or mobile advertising. I'll motivate this via some trends and data observations. One of the interesting aspects is business categories and geolocation: How far are people willing to travel to visit a restaurant? What about professional services like plumbers: are users less or more sensitive to how far those are compared to restaurants? I'll provide examples of how we use our open-sourced Map Reduce package (MRJob) to scale ML feature engineering and performance metric computation. I'll also provide details on our Machine Learning pipeline built using the popular python packages: numpy, scipy and sklearn. This talk would give you an in-depth overview of advertising systems, and why with increasingly sophisticated ad systems, in future we will wonder why we ever hated ads!	Soups Ranjan	Science	This talk would give you an in-depth overview of Real-Time Bidded (RTB) advertising systems, and why with increasing sophistication in ad-tech, in the future we will wonder why we ever hated ads. In particular, this talk will discuss technical challenges in ad systems and how we use Computational Advertising and Data Science to solve problems around Click Through Rate (CTR) Prediction, Auto-Bidding systems, Traffic Prediction, etc.	Novice	Data Science in Advertising: Or a future when we love ads	Friday	2015-04-10 12:10:00	2015-04-10 12:55:00
Interest and activity in childhood computing education continues to grow on all fronts, from government-sponsored initiatives to our own Python community.  Finding age-appropriate materials and environments that are educational and motivating has always been a challenge, especially for younger coders. Meanwhile, Minecraft has become a massive cultural phenomenon, capturing the hearts and minds of our youth. Many millions of hours have been spent in Minecraft, shaping and crafting worlds and capturing the imaginations of its players. It stands out as a fun, motivating platform that encourages exploration and play.  This talk will discuss the importance of play in education, the basic principles of motivation, and how it relates to teaching programming. How does Minecraft and its virtual environment solve these problems?  We will discuss the various tools and methods that can be used to allow Python-based interactions with the Minecraft world. The available Python APIs for Minecraft will be covered along with example curriculum and projects. The tools and environments discussed will cover appropriate requirements for both PC version of Minecraft and Minecraft PI; we will cover how to set up appropriate learning environments for your own use. Hear about experiences and successes in other communities. Outcome: Parents and educators will walk away with an understanding of Minecraft, its capabilities, and its significance in education. They will also learn how to teach Python programming through play within the Minecraft world. Attendees will receive references to materials that can be used to teach Python and steps required to setup learning environments.	Kurt Grandis	Education	Interest and activity in childhood computing education continues to grow. Meanwhile, Minecraft has become a massive cultural phenomenon as a fun, motivating platform that encourages exploration and play. This talk demonstrates how Python can be used to teach programming while exploring the world of Minecraft. We will cover how to set up learning environments, curricula, and case studies.	Novice	Exploring Minecraft and Python: Learning to Code Through Play	Friday	2015-04-10 10:50:00	2015-04-10 11:20:00
Working with Hadoop using Python instead of Java is entirely possible with a conglomeration of active open source projects that provide Python APIs to Hadoop components. This tutorial will survey the most important projects and show that not only is Hadoop with Python possible, but that it also has some advantages over Hadoop with Java. The reasons for using Hadoop with Python instead of Java are not all that different than the classic Java vs. Python arguments. One of the most important differences is not having to compile your code by instead using a scripting language. This makes more interactive development of analytics possible, makes maintaining and fixing applications in production environments simpler in many cases, makes for more succinct and easier to read code, and so much more. Also, by integrating Python with Hadoop, you get access to the world-class data analysis libraries such as numpy, scipy, nltk, and scikit-learn that are best-in-breed both inside of Python and outside. Students will be surprised at how quickly they can get up and running with Hadoop when using Python. In this tutorial, we will talk about the following libraries and approaches and will guide students through a series of exercises:  Interacting with files in the Hadoop Distributed File System with the snakebite Python module to store potentially petabytes of data Writing MapReduce jobs with the mrjob Python module to analyze large amounts of data over potentially thousands of nodes Writing MapReduce jobs with Apache Pig (a higher-level data flow language) in conjunction with Python user-defined functions  In addition to these topics, we'll briefly cover the state of Python support for other Hadoop ecosystem projects, such as HBase, Hive, Spark, Storm, Flume, Accumulo, and a few others.	Donald Miner	Databases	In this tutorial, students will learn how to use Python with Apache Hadoop to store, process, and analyze incredibly large data sets. Hadoop has become the standard in distributed data processing, but has mostly required Java in the past. Today, there are a numerous open source projects that support Hadoop in Python and this tutorial will show students how to use them.	Intermediate	Hadoop with Python	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
The novice or occasional user of the Pandas dataframe too often finds themselves lost in a forest of possible next moves. They try calling groupby() but the result an opaque object instead of a reorganized dataframe. They attempt a pivot() but cannot understand why the result is different from what they expected. The examples for stack() and unstack() look very nearly like the operations they want to perform, but they can never remember which is which without the documentation. This tutorial will help students rebuild their mental model of the Pandas dataframe from the ground up, starting with the structure of the dataframe and its indexes and then progressing through a complete tour of all of the operations that dataframe methods offer. Symmetries and contrasts will regularly be drawn between the methods and operations to help make it as easy as possible to remember them all, and to help relate the vertical and horizontal indexes along the edges of the dataframe. The tutorial will show Pandas use in both plain Python files and also in the IPython Notebook. Students will be encouraged to use Anaconda or another distribution that gives them both Python and all the standard science and numeric tools up-front without requiring further installation steps. At each stage in the tutorial, students will be given a short lecture and demonstration, allowed to ask questions, then be presented with a series of short dojo-like exercises that build their knowledge of each maneuver by progressing from simple to fairly complex data manipulations. As each feature is learned, students will then be challenged to use it in combination with features learned earlier in the tutorial — a mechanism that should improve retention of the complete set of possible method calls. The exercises will be hand-written and tailored to share three features. First, the examples will try to re-use dataframes whenever possible, so that students quickly become familiar with the data layout in each one of them and can more easily focus on the next maneuver they are learning. Second, the example dataframes will each be rather short — about one or two screens-full of data — so that the user has a more complete picture of “where their data is going” with each operation than would be possible with a larger data set. Finally, each example will be semantically rich and display common-sense relationships among the values present: there will be none of the vast arrays of randomly-generated random numbers that seem so common in scientific Python tutorials, but that give the learner’s mind nothing familiar to grasp as they stare at the output and wonder what relation the output numbers have to the inputs.	Brandon Rhodes	Python Libraries	The typical Pandas user learns one dataframe method at a time, slowly scraping features together through trial and error until they can solve the task in front of them. In this tutorial you will re-learn how to think about dataframes from the ground up, and discover how to select intelligently from their abilities to solve your data processing problems through direct and deliberately-chosen steps.	Intermediate	Pandas From The Ground Up	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
While Python is sometimes maligned as too slow for real world applications, many scientists, statisticians, and other data-oriented programmers find it to be efficient and powerful for large-scale data analytic tasks. The vast majority of this type of data analysis in Python is performed using NumPy, a package which extends Python with a powerful array-oriented computing interface. These arrays are flexible enough to handle all kinds of data: scientific imaging, sales records, statistical model parameters, logfile results, and more. The tools in NumPy form the core of other well-known Python data science packages such as Pandas, Scikit-Learn, SciPy, Matplotlib, and many more. Designing efficient data-intensive algorithms in Python requires not just using NumPy, but using it effectively. In broad-brush, this amounts to replacing slow loops over datasets with more efficient vectorized operations. In this talk I’ll cover briefly why loops in CPython tend to be slow, and why vectorizing these operations using NumPy can often provide speedups of 100-1000x in many cases. I’ll go on to introduce the four practical concepts essential to fast data analytics using NumPy: aggregation functions, universal functions, broadcasting, and fancy indexing. With a firm understanding of these four patterns, you’ll be well on your way to writing fast & efficient data-intensive code in Python.	Jake VanderPlas	Science	NumPy, the core array computing library for Python, provides tools for flexible and powerful data analysis, and is the basis for most scientific code written in Python. Getting the most out of NumPy, though, might require slightly changing how you think about writing code: this talk will outline the basic strategies essential to performing fast numerical computations in Python with NumPy.	Intermediate	Losing your Loops: Fast Numerical Computing with NumPy	Friday	2015-04-10 16:30:00	2015-04-10 17:00:00
This tutorial aims to cover a wide assortment of advanced topics related to modules, packages, and the import statement.  Topics will include, but are not limited to the following:  Basics of modules and packages. What can be imported? Module compilation (.pyc files, etc.) Construction of sys.path Namespace packages Virtual environments Circular module dependencies Package relative imports Module splitting (splitting modules into multiple files) Import hooks Module imports and threads Module reloading 	David Beazley	Python Core (language, stdlib, etc.)	All Python programmers use the import statement, but do you really know how it works and what it allows?  This tutorial aims to take a deep dive into every diabolical issue related to modules, packages, and imports.   When we're done, you'll finally be ready to unleash your million line micro framework on the world!	Experienced	Modules and Packages: Live and Let Die!	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
The terminal emulators we run so many of our programming tools in are more powerful than we remember to give them credit for, and the key to that power is understanding the interface. This talk will cover terminal colors and styles, writing to arbitrary portions of the screen, handling signals from the terminal, determining the terminal's dimensions, scrollback buffer behavior and relevant environmental variables. Terminal programming can get hairy; along the way we'll deal with encoding issues, consider cross platform concerns, acknowledge 4 decades' worth of standards for terminal communication, and consider that humans at interactive terminals may not be the only users of our interfaces. By gaining an understanding of these issues, we'll be able choose from the abstractions over them offered by Python libraries Urwid, curses, and Blessings.	Thomas Ballinger	Python Libraries	"Have you ever wanted to add a status bar to your command line program?
Or maybe color the output a bit? Or do you want to write a fullscreen terminal application like ls, top, vim, or emacs? Then you need to speak a bit of terminal! This talk describes how to talk to your terminal from scratch and goes on to show why Python libraries Blessings and Urwid are so awesome."	Novice	Terminal whispering	Sunday	2015-04-12 13:50:00	2015-04-12 14:20:00
This carefully constructed course will take a programmer with a basic understanding of Python to the next level. You should feel comforable with Python loops, variables, functions, and classes. From there we build your knowledge and cover some of the more exciting aspects of Python that tend to bite new Python programmers. With a unique, fast-paced combination of lecture and lab, the student will not only listen to the material, but try it out themselves. In addition, attendees will recieve a copy of the slides and a cheatsheet covering the material. Bring a laptop with Python (2 or 3) installed and a desire to learn the basics.	matt harrison	Python Core (language, stdlib, etc.)	Are you new to Python and want to learn how to step it up to the next level? Have you wondered about functional programming, closures, decorators, context managers, generators, or list comprehensions and when you should use them and how to test them? This hands-on tutorial will cover these intermediate subjects in detail, by explaining the theory behind them then walking through examples.	Intermediate	Hands-on Intermediate Python	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
A recommendation engine is a software system that analyzes large amounts of transactional data and distills personal profiles to present its users with relevant products/information/content. We see them in a wide variety of domains and applications and they help us navigate the overwhelming choice that we face everyday. This tutorial will formally introduce the concepts and definitions of the recommendation systems literature and will quickly move on to an iterative process for building a minimal reco engine. In the process, we'll learn about the building blocks for scientific computing in Python: NumPy and (more recently) pandas.	Diego Maniloff,Christian Fricke,Zach Howard	Science	In this tutorial we'll set ourselves the goal of building a minimal recommendation engine, and in the process learn about Python's excellent Pydata and related projects and tools: NumPy, pandas, and the IPython Notebook.	Intermediate	Hands-on with Pydata: how to build a minimal recommendation engine.	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
Deployment is a simple idea in theory but can be difficult in practice.  Many mechanisms exist but few work very well with python being deployed across multiple operating systems in a service oriented architecture. One issue we've faced with a SOA is that you can end up with many projects rolling their own deployment mechanism which results in many half-baked deployment pipelines.  This can create a large pain point in transitioning people from one team to another.  Bug fixes can be committed quickly but it can be a royal pain in getting the changes out and live. To help alleviate that pain we've come up with a generic package-centric deployment strategy that focuses on Python but also supports other languages like NodeJS.  The deployment strategy leverages technologies like Jenkins, Pip, Virtualenv, and Fabric to allow for quick deployments that result in code being isolated from other services and native libraries on the node. This talk will introduce a deployment pipeline that uses Python packages as the main deployment strategy and the mess it helped clean up.  I will go into how the pieces fit together for this deployment, some of the successes had with this mechanism as well as some of the pain points in using it.	Dan Tracy	Systems Administration	Gone are the days where creating system packages or scp-ing tar balls were required for deployment.  With Pip, Fabric, and Jenkins we've  developed a pipeline to simplify deployments and rollbacks that dove-tails into configuration management and virtualization.  New machines can come fully deployed and ready to rock at a moments notice allowing you to scale out nodes quickly and painlessly.	Novice	Ship it: Deployments with Pip	Saturday	2015-04-11 14:35:00	2015-04-11 15:05:00
IPython started in 2001 simply as a better interactive Python shell. Over the last decade it has grown into a powerful set of interlocking tools that maximize developer productivity in Python while working interactively. Today, Jupyter consists of an IPython kernel that executes user code, provides many features for introspection and namespace manipulation, and tools to control this kernel either in-process or out-of-process thanks to a well specified communications protocol implemented over ZeroMQ. This architecture allows the core features to be accessed via a variety of clients, each providing unique functionality tuned to a specific use case:   An interactive, terminal-based shell with capabilities beyond the default Python interactive interpreter (this is the classic application opened by the ipython command that most users are familiar with).   A graphical, Qt-based console that provides the look and feel of a terminal, but adds support for inline figures, graphical calltips, a persistent session that can survive crashes of the kernel process, and more. A user-based review of some of these features can be found here.   A web-based notebook that can execute code and also contain rich text and figures, mathematical equations and arbitrary HTML. This notebook presents a document-like view with cells where code is executed but that can be edited in-place, reordered, mixed with explanatory text and figures, etc. The notebook provides an interactive experience that combines live code and results with literate documentation and the rich media that modern browsers can display:     A high-performance, low-latency system for parallel computing that supports the control of a cluster of IPython engines communicating over ZeroMQ, with optimizations that minimize unnecessary copying of large objects (especially numpy arrays). These engines can be controlled interactively while developing and doing exploratory work, or can run in batch mode either on a local machine or in a large cluster/supercomputing environment via a batch scheduler.  These tools also increasingly work with languages other than Python, and we are renaming the language independent frontend components to Jupyter in order to make this clearer. The Python kernel we provide and the original terminal-based shell will continue to be called IPython. In this hands-on, in-depth tutorial, we will briefly describe IPython's architecture and will then show how to use the above tools for a highly productive workflow in Python.	Thomas Kluyver,Kyle Kelley	Python Libraries	IPython and Jupyter provide tools for interactive and parallel computing that are widely used in scientific computing, but can benefit any Python developer. We will show how to use IPython in different ways, as: an interactive shell, a graphical console, a network-aware VM in GUIs, a web-based notebook with code, graphics and rich HTML, and a high-level framework for parallel computing.	Intermediate	IPython & Jupyter in depth: high productivity interactive and parallel python	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
In Python, we're trying to solve packaging problems in our own domain, but maybe someone else already solved most those problems. In the talk I'll show how I develop and deploy Python projects that can be easily mixed with non-Python dependencies. http://nixos.org/ project will be demonstrated to replace technologies in our stack: pip, virtualenv, buildout, ansible and jenkins. Following technologies will be presented:  Nix: Package Manager and minimalistic DSL NixOS: declarative Linux Distribution NixOps: cloud deployment tool Hydra: Continuous Integration server for Nix 	Domen Kožar	Systems Administration	Applying functional programming ideas to solve the problem of packaging software and configuration of systems in a stateless and deterministic way. Nix project addresses those problems in unique way based on academic research that has been applied to real world software collections in last 10 years.	Experienced	Rethinking packaging, development and deployment	Saturday	2015-04-11 15:15:00	2015-04-11 15:45:00
Sometimes, you want to modify a user experience based on rate, but first, you need a way to track how fast s/he is doing something. How to go about doing this? “Classic” rate tracking involves incrementing a count when a user performs a specific action of interest in a given period of time. We’ll discuss why this method is not as effective as we would like, especially given the goal of rate limiting, or restricting access based on rate, namely:   no way to archive this data the difficulty of implementing a sliding time window the lack of granularity that we want for writing rate limiting rules  Next, we will explain the “velocity engine,” the more evolved rate tracker that we built in Python at Eventbrite. We’ll cover:  our use of the redis-py library to implement a Redis data store and how Redis versions 2.6 and 2.7 affect our implementation how we generate keyspaces and facets in Redis, as well as the partitioning of each bucket translating from the Redis internal structure to a more readable list of rates our expiration strategy for keyspaces and the “housekeeper” module that keep Redis clean despite tons of rate data how this smarter implementation allows us to do more nuanced rate limiting by writing rules with a greater granularity  You will leave this talk with a better understanding of rate tracking and how smart rate tracking is a great foundation to set for better rate limiting.	Mica Swyers,Jay Chan	Best Practices & Patterns	This talk provides an introduction to rate tracking as well as an explanation of a particularly cool way to implement it. You will learn what rate tracking is, why you would want to do it, and then how you can use build a Redis-backed “velocity engine”  in Python to do just that.	Novice	Finding Spammers & Scammers through Rate Tracking with Python & Redis	Sunday	2015-04-12 13:50:00	2015-04-12 14:20:00
I've worked at many institutions with many programming languages over the past 8 years They all have technical debt. Putting on a band-aid and ignoring the real issues can be disastrous. We'll go through several case studies, review big red flags, and learn how to start chipping away at the problem with confidence.	Nina Zakharenko	Best Practices & Patterns	Technical debt is the code monster hiding in everyone's closet. If you ignore it, it will terrorize you at night. To banish it and re-gain your productivity, you'll need to face it head on.	Novice	Technical Debt - The code monster in everyone's closet	Saturday	2015-04-11 12:10:00	2015-04-11 12:55:00
In this talk, I describe what a hash function is, and how the unique properties of a hash function can be used to provide abstractions like the hash table. I will talk about bloom filters, a unique data structure that provides set membership information and extreme compression, at the cost of not being sure whether it is entirely correct.  We'll learn how to choose hash functions for data structures and for security, what an avalanching hash function is, and what differentiates a cryptographic hash function from a non-cryptographic hash function.  We will learn how modern web security is intimately tied to the humble hash function, how to hash passwords, and how not to hash passwords.	Curtis Lassam	Other	"Our trusty friend, the hash function, is as crucial to programming as linked lists or recursion, but it doesn't always get the press that it deserves. 

We're going to talk about hash functions, some data structures involving hash functions, the stately bloom filter, and the security implications of password hashing."	Novice	Hash Functions and You: Partners in Freedom	Sunday	2015-04-12 14:30:00	2015-04-12 15:00:00
"Why would you need to experiment if it's pure mathematics? Don't you just spend your whole day writing down complicated computations using weird symbols and popping theorems out of your head? This talk is here to show you that pure mathematics is not always like this. We're going to explore some combinatorics questions like ""how many binary trees of size 42 are there?"" or ""What does a random binary tree of size 1000 looks like?"" and see how computer exploration plays an essential role in finding and proving new results. Doing so, we'll see what kind of code and structure we use and understand the aim of pure mathematical programming. All examples will be written in python using the mathematical software Sage. So this is also an occasion to discover about Sage through actual research based examples and demo. No previous Sage or mathematical knowledge is needed."	Viviane Pons	Science	Pure mathematics is not always big formulas written on endless notebooks, it can also be hidden behind python code. In combinatorics, we study classical computer science objects like trees or graphs with a mathematical perspective. This talk aims to show how computer exploration and experimentation can be used to discover and prove new mathematical results.	Novice	Experimental pure mathematics using Sage	Friday	2015-04-10 11:30:00	2015-04-10 12:00:00
I will walk through the practicalities of building a simple video game from scratch, starting with presenting one approach to structuring the game code to keep it sane. I will talk about what libraries are available and then focus on the facilities present in the library used in the tutorial. I will then walk through the development of a simple game during which the attendees will code the game. Once the game is developed I will talk about potential further development that possibilities and use the remaining tutorial time to encourage and assist attendees in their efforts to do so. The game developed will cover the key game-writing skills of controlling what appears on the screen (including tile mapping and animation), loading resources, handling user input and simulating the environment within the game. There will be demonstrations and discussion of the various tools that may be used to create game assets (tile maps, sprites and sound effects.) The tutorial will also cover packaging the game for distribution both via PyPI and as a stand-alone executable. This includes the mobile platforms Android and iOS.	Richard Jones	Gaming	This tutorial will walk the attendees through development of a simple game using Kivy with time left over for some experimentation and exploration of different types of games.	Novice	Introduction to game programming with Kivy	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
Which tests are worth writing and which aren't? Chasing complete coverage is a waste of effort, and leads you to write bad tests. I'll describe two kinds of bad tests and show examples, and I'll share my principles for designing good tests. By choosing where to focus your efforts, and importantly where not to test, you can achieve a high degree of confidence in the correctness of your code without sacrificing speed, or risking unreliable tests. Next we will examine in detail the question of test assertions. The best tests assert about every possible output from a function or class under test, right? Of course it's important to thoroughly test your code. I will demonstrate how to structure tests so that failures point you immediately in the direction of the issues in your codebase, and how to use good object-oriented principles to make your tests serve as both readable and executable documentation of your code's behavior. Finally, we will examine the thorniest of testing scenarios, the infamous integration test. Many Python programmers favor the Mock library, which, if used carefully, is indeed a powerful tool. It should be considered an advanced weapon in your testing toolkit, to be used only sparingly and with great care, for mocking carries with it great risks: you might end up testing nothing! I'll show how to avoid the risks of overly-magic testing, and where parts of the Mock library are safe.	Dan Crosta	Testing	In a highly dynamic language like Python, testing is even more critical than in compiled or more static languages. Like any other code we produce, tests can be either good or bad. This talk explores three fallacies of testing, and the mistakes and bad habits these fallacies encourage; and shows how to write good tests which help assure proper behavior without impeding development progress.	Novice	Good Test, Bad Test	Saturday	2015-04-11 10:50:00	2015-04-11 11:20:00
"Overview It is a truth universally acknowledged that the admin is an important component of the Django framework, and knowing how to make efficient use of it can save you days or weeks of development. The Django tutorial is a great place to take your first steps with the admin, but it can often take a bit of searching to learn how to use some of the more advanced features. The goal of this tutorial is to bridge the gap between the Django tutorial and the reference documentation of the Django admin by using real examples.   We will use a fully-functional (though fictional) Django project to build an admin interface to support the librarians at a local library. The interface will allow them to add and edit patrons and resources (books, CDs, DVDs, etc.) as well as manage fines for overdue items. They will be able to make comments on various models as well. The tutorial begins with a discussion of what a library might need in terms of an administrative interface for the librarians.  We then cover the models that are available in our demonstration project (https://bitbucket.org/jacinda/admin-library). We then proceed through a commit-by-commit progression of our repository that demonstrates the evolution of this admin interface.   While not required, students will get more out of the tutorial if they have a computer with them that is capable of running the code in the admin-library repository.  The repository includes the necessary files to use a virtual machine and vagrant or can be setup easily within a virtualenv running on the metal of most systems.  Students are expected to have some familiarity with Django but even novices will be able to get a lot of information from this tutorial (particularly the first half). Ground to Be Covered We move quickly through some more basic ""review"" examples that more experienced Django users will be familiar with, like changing the default URL, the title text and some idiosyncrasies of using Django's AbstractUser with the admin.  We also cover adding models, modifying the display of those models, changing field / fieldset orders, adding help text and a laundry list of ""basic hygiene"" admin tasks. The bulk of the tutorial then covers more intermediate / advanced topics within the admin, including the use of custom readonly fields to allow certain staff members the ability to edit certain fields while restricting other staff members, the potential performance impact of including different fields in list_display, and how to use custom filters, views, and templates to add additional functionality. Based on audience interest and timing, the tutorial will cover audience questions about the admin and either try to demonstrate answers in real time or provide a link later to an example."	Jacinda Shelly	Web Frameworks	"The admin interface is widely considered a ""killer feature"" of Django. At its most basic, you can just register all your models and be on your way, but there's so much more available within Django's admin. This tutorial takes you step by step through the creation and progressive improvement of an admin interface for a fictional library (all code is publicly available)."	Intermediate	Delving into the Django Admin	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
Using a Python Flask REST API web service for an AngularJS front-end application a team at Boston University will be delivering STEM (Science Technology Engineering and Mathematics) educational content for Deaf children, K-12.  (This work was funded by grant from the Commonwealth of Massachusetts) Python was chosen because of it's clarity, power, extensibility, and Pythonic personality.  This project complements our other initiative which is to resurrect and continue The Summer Academy started by Richard Ladner), an academically challenging program designed for deaf and hard-of-hearing students with skills in math or science who may be considering careers in computing, with the goal of encouraging them to consider college majors and careers in computing fields. The Summer Academy had occurred annually at the University of Washington (UW) since 2007-2012.  We are now re-visioning the Academy specifically as a Python Summer Academy for DHH to be held first in 2015 at Boston University and invite the Python community to share and take part.	en zyme	Community	ASL, like Python, is a language which is both fun and powerful.  We have used Python to build a tool, ASL STEM for the DHH community which will teach STEM terminology using ASL exclusively.  We are also building a summer program to teach Python in English/ASL to DHH students.	Novice	Pythons are Deaf, So are Some Pythonistas	Saturday	2015-04-11 14:35:00	2015-04-11 15:05:00
"The brain is the most impressive computational device that we know about, and yet is just a collection of simple computational devices called neurons. Its power comes in the sheer number of neurons, and the even sheerer number of connections between neurons. Historically, trying to simulate the brain meant trying to simulate an individual neuron accurately. Early simulation programs were implemented in C or C++, with custom scripting languages. I will show how Python bindings to these programs have made them significantly easier to use. I will also show more flexible tools for low-level simulation written entirely in Python, which have made brain simulation even easier -- it's possible to simulate thousands of complex neurons on a typical desktop computer! However, this is quite far off from the human scale of >100 billion neurons. How can we ever hope to reach this scale? Some research groups have created specific hardware to simulate neurons. These are called ""neuromorphic"" computing devices, and the creators of these chips have also turned to Python as a way to program their chips to run brain simulations. At the University of Waterloo, we have been working on a new approach to scaling up brain simulations, and a new Python package to support that approach. Instead of focusing on biologically accurate neurons, we focus on how to connect neurons together such that they can compute interesting functions. Functions that we've implemented so far include recognizing digits in images, controlling a simulated arm, gambling, and solving a simple test of cognitive ability. I'll show how Python allows us to quickly simulate brain models that carry out these functions. I will also discuss how Python allows us to use those biologically accurate neurons, and even to take advantage of neuromorphic hardware, by only changing a few lines of code."	Trevor Bekolay	Science	Simulating the human brain is often the subject of science fiction, but how close are we really? In this talk, I'll survey cutting edge research projects that use Python to simulate the brain, focusing on Nengo, which was used to build Spaun, the largest functional brain simulation to date.	Intermediate	How to build a brain with Python	Friday	2015-04-10 17:10:00	2015-04-10 17:40:00
This tutorial will cover how easy it can be to build your own REST API using Django and Django REST Framework.  It is meant to be a course for people that have at least an introductory knowledge of Python, but are not familiar or comfortable with the Django world.  The tutorial would start with a quick walkthrough of installing the relevant Django REST Framework version.  From there, we will actually start coding a REST API for a simple Restaurant Menu application.  This will include covering the necessary building blocks that are required.  In building our Restaurant Menu application, we will control API access levels through Django Users and Groups.  We will also go over the benefits of the Admin interface and the Browsable API interface.  Once our base API is ready, we will start looking at advanced use cases.  Based on time and attendee interest, we may be able to cover additional topics along the way or at the end.  Those additional topics could be advanced API functionalities or coverage of general questions.	Kenny Yarboro	Web Frameworks	Using a combination of Django and Django REST Framework, we will build a Restaurant Menu that can be managed via a REST API. Starting from the install of the Django REST Framework, we will build our way to a functional API that meets the needs of developers and end-users. You will walk away with an understanding of the basic concepts of REST APIs and a working sample project.	Novice	Building a REST API Using Django & Django REST Framework	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Learn how to extend your Python programs with high-performance functions written in Rust. Plus, get a brief overview of the Rust programming language, what it's good at, and why you might prefer it over C for your next project requiring low-level optimization.	Dan Callahan	Other	Rust is a new systems programming language from Mozilla that combines strong compile-time correctness guarantees with fast performance... and it plays nice with ctypes! Come learn how you can call Rust functions from Python code and finally say goodbye to hacking C!	Intermediate	My Python's a little Rust-y	Friday	2015-04-10 14:35:00	2015-04-10 15:05:00
Do you litter your code with print and log statements to figure out why it isn't doing what you expected? If so, this talk is for you! The Python Debugger is an easy to use debugging tool once you learn the commands. For those that haven't been exposed to it yet, it may be overwhelming. This talk aims to cover all of the most commonly used commands for day to day debugging sessions. It will also briefly cover a few pdb alternatives to make debugging easier and ways to integrate pdb into popular editors. For each command, the audience will learn what the command does, its shortcut and how it is used. The usage examples will be done by running pdb against code during the presentation. This will give the audience the chance to see live examples of how pdb can be used to debug and investigate Python code. Audience members should leave the talk with enough knowledge to start debugging and inspecting their own programs right away. With the power of pdb in your toolbelt, you'll never be left in the dark, wondering why that code isn't doing what you expected. You'll be able to dig in and get to the bottom of the issue faster than ever.	Clayton Parker	Python Core (language, stdlib, etc.)	This talk will be an introduction to the most commonly used Python Debugger commands and what they do. Learn how to navigate and inspect code from the pdb prompt so you can better understand how it works. The Python Debugger is a valuable debugging tool for all levels of Python programmers. You should walk away being able to debug the next Python code you encounter!	Novice	So you think you can PDB?	Saturday	2015-04-11 17:10:00	2015-04-11 17:40:00
In this talk we'll explain what happens behind the scenes when we try to establish a secure connection to a web site.  We'll cover the common security flaws in popular TLS implementations like OpenSSL, and see how these issues can be avoided if we have a good well-designed TLS implementation in a high level language like Python.  Finally, we'll discuss how the API design of OpenSSL leads to application bugs, and a lack of abstract secure defaults leads to insecure applications.	Ashwini Oruganti,Christopher Armstrong	Security	Given recent increases in hostile attacks on internet services and large scale surveillance operations by certain unnamed government organizations, security in our software is becoming ever more important. We'll give you an idea of how modern crypto works in web services and clients, look at some of the common flaws in these crypto implementations, and discuss recent developments in TLS.	Novice	Introduction to HTTPS: A Comedy of Errors	Friday	2015-04-10 11:30:00	2015-04-10 12:00:00
Twenty-odd years ago, industry windbags proclaimed that the golden age of reusable software components was around the corner, thanks to the miracle cure of object-oriented programming languages. This kind of magical thinking led, in a long roundabout way, to atrocities like AbstractSingletonProxyBeanFactory (don't ask: it's a Java thing). But reusable code is not an impossible objective, just a difficult one. After a couple of decades of trying, often successfully, to write good reusable code, I've learned a few useful tricks. If you've ever wondered whether you should write a class or a function, or when side effects are appropriate, or how much testing is enough, this is the talk for you.	Greg Ward	Best Practices & Patterns	Learning to write high-quality, reusable code takes years of dedicated work. Or you can take a shortcut: attend this talk and learn some of the tricks I've figured out over a couple of decades of programming.	Intermediate	How to Write Reusable Code	Saturday	2015-04-11 10:50:00	2015-04-11 11:20:00
Twitter's social network is endlessly fascinating because of its many different connection channels: there are hashtags, followers, retweets, and replies, all connecting users in different ways. Using the network analysis package NetworkX, we'll take a look at how to make sense of these channels. We'll cover some of the basics of network theory, including types of networks and how measure influence in a network. We’ll use the Twitter API to gather data for our analysis, and then apply the network theory we learn to that data. Students will leave with knowledge of how to think about networks from a network theory perspective and may even find out something interesting about their own Twitter network. Students should have an intermediate knowledge of Python, including the ability to write functions and understand iterables. Knowing how to use IPython Notebook will also be helpful, since the materials will be in that format. Having both NetworkX and IPython notebook, as well as matplotlib, which we’ll use for visualization, installed prior to the tutorial is necessary, as we’ll only spend a few minutes covering installation. These packages can be pip installed, or can be installed through a distribution like Anaconda or Enthought Canopy.	Sarah Guido,Celia La	Python Libraries	Twitter's network is fascinating because of its connectivity: there are hashtags, followers, retweets, and replies. Using the network analysis tool NetworkX, we'll look at how to make sense of these channels. We'll cover the basics of network theory, including types of networks and how measure influence, and we'll apply those measures to our investigation of Twitter's network.	Intermediate	Twitter Network Analysis with NetworkX	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
The Walt Disney Animation Studios has a long history of creating acclaimed animated films and continues to be an industry leader with regards to artistic achievements, storytelling excellence, and cutting-edge innovations.   Since the 1923 release of Snow White they’ve been pushing forward technology in the art of movie making.  This push continues in the modern day with classics such as Oscar winning box office hit “Frozen” and Oscar nominated hits “Wreck-It Ralph”, “Tangled”, “Bolt”, “Treasure Planet”, and “Dinosaur”. One of the most common questions we get when attending PyCon is “Why are you here?”  People seem confused that technology, especially Python is used in the making of animated films.   To dive into exactly where Python is used without context would be confusing so Paul will give the audience some background on the Walt Disney Animation Studios.  He will talk about what we’ve done and what we are currently working on.  The main part of the talk is describing the production process whilst imparting this information he will interject where technology and specifically Python comes into play.   He will describe the tools in each area and the tech stack used to create them. He will wrap up the talk with describing how our Studio is organized, how we develop software, and venues we use to share our technology with others.	Paul Hildebrandt	Gaming	Paul will take you through the process of making of a Disney movie.  He will use examples from Big Hero 6 to explain and illustrate the steps in making a movie and explain where technology, specifically Python, is involved.	Novice	Inside the Hat: Python @ Walt Disney Animation Studios	Friday	2015-04-10 12:10:00	2015-04-10 12:55:00
A property graph database represented by G = (V, E, λ) is basically a set of vertices (V) connected by edges (E), where each element can contain properties (λ) as key-value pairs. The most important thing of a graph database is that it provides index-free adjacency for fast global lookups in constant time, vs exponential time join-on-join in relational databases; while document databases (a.k.a. NoSQL) encourages denormalization and data embedding. My favorite graph database is Titan, because it allows me to use the storage backend of my preference (Cassandra) and index backend of my preference (Elasticsearch). Titan also provides a seamless integration with Gremlin, which is the graph traversal language created for Blueprints to manipulate Property Graphs. However, Titan is written in Java, and Gremlin provides Groovy syntax. There are Java frameworks, like Rexster, that expose the graph database functionality through a REST API. Although this solution can work for simple use cases, as you need to execute more complex traversals, the Rexster API falls short because it provides just the basic CRUD operations (and read operations executes very simple traversals). For Python programmers, interfacing your program with Rexster API to communicate with Titan generates too much HTTP overhead, and it’s limited to what Rexster functionality can provide. Instead, you can create your own a set of database models that expose Gremlin-like operations and inherit Blueprints Pipes architecture; and allows you to execute complex traversals and get the most of your graph database, without imposing a data model from your code. For achieving this, we must follow especially the S part of SOLID design (Single responsibility principle). You want to create a models of vertices that ONLY return vertices belonging to the same namespace and only manipulate those vertices. The same principle applies for edges. Following this design principle, you can create factory classes for vertices and edges, that implement the most commonly used traversals (like g.v, g.V, g.V.has, g.out,g.outE, etc) and then create a set of models where each model correspond to a namespace (in the case of vertices) or a label (in the case of edges). Most of this is achieved by the correct use of Factory Pattern, Pipes and Filters and Decorators.	Elizabeth Ramirez	Databases	Creating and using models from a graph database can be quite different to the ones used for row/column/document-oriented databases, in the sense that the same query patterns could differ significantly in structure and performance. This session will present how to create models in Python for Titan property graphs, that allow you to manipulate graphs as if you were querying with Gremlin DSL.	Intermediate	Graph Database Patterns in Python	Saturday	2015-04-11 15:15:00	2015-04-11 16:00:00
Businesses can rise or fall on the margins created by application performance. Conversions, revenue, and traffic all increase dramatically as websites get faster. Giant after internet giant has produced metrics reaffirming the importance of fractional seconds of response time. Performance is not an easy problem to solve, though. Intuitively applying optimizations and hoping for the best produces poor results. Inferring application characteristics from operating system metrics can mislead. Only application instrumentation can provide deep insight into application performance. Instrumenting apps is hard, though, and interpreting the results can be even harder. Profilers and system metrics are the first tools most engineers reach for, but neither is very good at understanding the performance implications of application behavior. Understanding the performance of production applications requires tools that measure the performance of production applications. This sort of instrumentation comes in many forms. Developers often write their own monitoring endpoints. Etsy's statsd couples well with graphite as a tool to instrument an application by hand. Distributed tracing tools offer a different way of looking at latency, by putting it in the context of a request/response cycle. Each of these tools has a role in uncovering some aspect of application performance.	Geoff Gerrietts	Best Practices & Patterns	Everyone knows poor performance when they see it, and performance concerns affect every application -- web applications more than most. But finding performance problems can be extraordinarily difficult, and requires an analytical approach coupled with good instrumentation. This talk explores approaches to instrumentation and what that instrumentation can tell you.	Intermediate	Performance by the Numbers: analyzing the performance of web applications	Sunday	2015-04-12 14:30:00	2015-04-12 15:00:00
" Data munging for predictive modeling with pandas and scikit-learn  Building predictive models first requires shaping the data in the right format to meet the mathematical assumptions of machine learning algorithms. In this session we will introduce the pandas data frame datastructure for munging heterogeneous data into a representation that is suitable for most scikit-learn models. In particular we address problems such as missing value imputation and categorical variables. We will illustrate those concepts by combining pandas-based feature engineering with scikit-learn Logistic Regression, Random Forests and Gradient Boosted Trees.  Model evaluation and selection  Building a predictive model is a fundamentally iterative process: design a model, train it, analyze errors, fix the model design and iterate. To iterate quickly in the right direction it is therefore very important to understand how models fail. This session will dive into methodological concepts and scikit-learn tools to evaluate models such as cross validation, overfitting and underfitting, regularization, plotting validation curves and learning curves. Finally we also cover how some parts of the model design can be automated via parameter search (exhaustive Grid Search or Random Search).  Working with text data  Machine Learning with text data can be very useful for social networks analytics for instance to perform sentiment analysis. Extracting a ""machine learnable"" representation from raw text is an art in itself. In this session we will introduce the bag of words representation and its implementation in scikit-learn via its text vectorizers. We will discuss  preprocessing with NLTK, n-grams extractions, TF-IDF weighting and the use of SciPy sparse matrices. Finally we will use that data to train and evaluate of a Naive Bayes classifier and a Linear Support Vector Machine."	Olivier Grisel	Science	This tutorial will offer an overview of common usage and methodological patterns when using Scikit-Learn to build predictive models. In particular we will highlight common strategies to deal with data with heterogeneously typed attributes with pandas dataframes, model evaluation and tuning. Finally if time permits we will explore the specificities of working with textual data.	Intermediate	Machine Learning with Scikit-Learn (II)	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
We will first explain the basics of ansible common usage ( ie, using yaml playbook for configuration management and orchestation ). Then, we will explore the plugins and modules systems, showing what can be extended from inventory, connexion and modules, and how people can add their own python code in the mix. Then we will conclude by looking at Ansible own API, to write specific code that reuse it to run on several systems.	Michael Scherer	Systems Administration	Ansible is a configuration management tool whose primary mode of operation involve using YAML to describe deployments and operations. However, it can do much more and be extended using python, which is what we will explore in this talk. Among others, we will see the plugins system for various part of the tool and how to reuse Ansible in a script.	Intermediate	Ansible beyond YAML	Saturday	2015-04-11 11:30:00	2015-04-11 12:00:00
"Introduction / A mysterious bug An outline of the Python interpreter in Python that Ned Batchelder and I were writing, the reason we set out to write it, and a mysterious bug we encountered Into the machine Introduction to bytecode  The definition of bytecode as an internal representation of Python code to the interpreter What it means to talk about ""compiling"" Python code when Python is an ""interpreted"" language Using dis to understand bytecode  The VM is a stack machine  Discussing the virtual machine as a stack machine Why bytecodes like BINARY_MOD don't have arguments What ""dynamic"" means  Executing Bytecode  The main loop of the CPython interpreter is a 1,500 line switch statement! Visualizations of the stack as code executes  Resolving the bug At this point I'll reveal the misunderstanding we had when first writing the interpreter Conclusion I'll close by restating what we learned and drawing analogies to other systems, if time allows."	Allison Kaptur	Python Internals	Have you ever wondered how the CPython interpreter works? Do you know where to find a 1,500 line switch statement in CPython? I'll talk about the structure of the interpreter that we all use every day by explaining how Ned Batchelder and I chased down a mysterious bug in Byterun, a Python interpreter written in Python. We'll also see visualizations of the VM as it executes your code.	Intermediate	Bytes in the Machine: Inside the CPython interpreter	Saturday	2015-04-11 13:40:00	2015-04-11 14:25:00
 It's 2015, and we live in a strange and wonderful world where we can play with a Python interpreter in our browser that has been compiled from Python to C to JavaScript through a seemingly miraculous transformation pipeline: PyPy → LLVM → Emscripten → JavaScript  This pipeline is full of jargon and computer science concepts that look intimidating, but the truth is that anyone attending PyCon can not only master them, but also play with and contribute to these exciting projects that are pushing the boundaries for where Python can be used. Attendees will leave the talk with a crisp understanding of the pipeline, background in the important compiler, interpreter, and language design concepts that make it possible, and a guaranteed desire to play with these exciting emerging technologies! Outline  Demo and overview of the pipeline. Why is this interesting? [2 minutes] What is PyPy? [5 minutes] Why PyPy and not CPython? What is LLVM? [5 minutes] RPython to LLVM translation: key concepts. Cool LLVM applications. What is Emscripten? [5 minutes] LLVM to JavaScript compilation: key concepts. Cool Emscripten applications. Putting it all together: PyPy → LLVM → Emscripten → JavaScript in your browser [1 minute] Brief analysis of performance, and tricky cases like graphics and using system resources [5 minutes] Is this the future of Python? [2 minutes] Food for thought (and experiments you might want to run!) Closing demo 	Jessica McKellar	Python Internals	We live in a strange and wonderful world where we can use a Python interpreter in our browser that has been compiled from Python to C to JavaScript. Attendees will leave the talk with a crisp understanding of the transformation pipeline that makes this possible, background in the important compiler and interpreter concepts, and a guaranteed desire to play with these exciting technologies!	Intermediate	Python in the browser: a weird and wonderful compiler journey from RPython to C to JavaScript	Friday	2015-04-10 10:50:00	2015-04-10 11:20:00
From day one, the Runscope architecture was built around the idea of small independent services that can be quickly written, deployed, and scaled up as we grow.  Core to this architecture are our service discovery and deploy tools.  Over time, we've standardized how we build and communicate with these services into two python libraries:  Smart-Service and Smart-Client.   This talk examines the lessons learned from building these libraries as well as service building patterns found in other platforms.  We also present a detailed look at how Runscope has built over two dozen services, serving over 1 billion requests a month, all while deploying to our cluster over 20 times a day -- and more importantly how you can replicate this to help you build better systems. The talk will show examples of Flask/Flask-Restful based servers and the important modifications we've made to help us operate dozens of services at scale.  We also will show code from our HTTP client that wraps Requests with service discovery, failover, and other useful features for reliably making API calls in our infrastructure.	Frank Stratton	Best Practices & Patterns	"At Runscope we've standardized the idea of small independent ""smart"" services that can be quickly built, deployed, and scaled. This talk examines lessons learned from writing these services as well as patterns found in other platforms. We present a detailed look at the code that allow us to build dozens of services, serving billions of requests, while deploying to our cluster over 20 times a day."	Novice	Smart services & smart clients:  How micro-services change the way you build and deploy code.	Friday	2015-04-10 14:35:00	2015-04-10 15:05:00
Do you know the difference between standard deviation and standard error?  Do you know what statistical test to use for any occasion?  Do you really know what a p-value is?  How about a confidence interval? Most students don’t really understand these concepts, even after taking several statistics classes.  The problem is that these classes focus on mathematical methods that bury the concepts under a mountain of details. This tutorial uses Python to implement simple statistical experiments that develop deep understanding.  Attendees will learn about resampling and related tools that use random simulation to perform statistical inference, including estimation and hypothesis testing.  We will use pandas, which provides structures for data analysis, along with NumPy and SciPy. I will present examples using real-world data to answer relevant questions.  The tutorial material is based on my book, Think Stats, a class I teach at Olin College, and my blog, “Probably Overthinking It.”	Allen Downey	Science	Statistical inference is a fundamental tool in science and engineering, but it is often poorly understood.  This tutorial uses computational methods, including Monte Carlo simulation and resampling, to explore estimation, hypothesis testing and statistical modeling.  Attendees will develop understanding of statistical concepts and learn to use real data to answer relevant questions.	Intermediate	Statistical inference with computational methods	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
Learning how to implement cryptography correctly is hard. Developers typically learn while doing, using online and local resources and trying and retrying until the code does what they want. Unfortunately, cryptography can't generally be learned in this manner as doing it wrong tends to be indistinguishable from doing it right without a significant amount of effort. This tutorial is designed to help developers over this hump. We'll be covering general cryptography principals and best practices as well as the following topics: Passwords & Authentication - We will cover general authentication topics to help developers choose between the various authentication schemes including generation methods like PDKDF2, scrypt or bcrypt and key based methods using asymmetric crypto. We will then cover how to implement these systems in Python with an eye towards usage in common frameworks. Data at Rest Encryption - Data in applications comes in a huge variety of forms. We will review options for encrypting data and the pros and cons of each method. Once we've covered the cryptographic primitives, we'll cover how to use them securely in common cases and how and when to extend them. Signing & Verification - Many applications don't want to encrypt data for various reasons (performance, debuggability, etc) but do want to be able to verify that information hasn't been tampered with or that it comes from a known, valid user. In this section, we'll cover the use cases and standards around signing & verifications and walk attendees through the implementation of these types of schemes. Key Management - All encryptions schemes are only as secure as their keys. In this session, we'll review the various types of key management for applications and review which type will be appropriate in different scenarios. We'll then walk through an implementation of one or more key management schemes using open source software.	Jarret Raim,Paul Kehrer	Security	The cryptographic world doesn't lend itself to the typical developer flow of learning while doing. Add that to the massive amount of bad or outdated information on the web and many developers are lost or worse, build insecure systems. This tutorial will introduce developers to modern cryptography with an eye towards practical scenarios around password management, encryption and key management.	Intermediate	What to do when you need crypto	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
The aim is to cover the basics of setting up a simple Django site, but using full, rigorous TDD at every step along the way. The tutorial is based on the first few chapters of my book, which is available (for free!) online for you to follow up with after the session, so that you can embed what you've learned.  www.obeythetestinggoat.com We'll learn:  how to set up functional tests with Selenium how to set up Django how to run Django unit tests how TDD actually works in practice:  the unit test / code cycle where we re-run the tests after each tiny, incremental change to the code all the basics of Django like views, models and templates.   We'll talk about what to test, what not to test, what the point of all this testing is anyway, you'll get a real hands-on feeling for how it works, and I promise to make it all at least moderately entertaining! And it's all in Python 3 :)	Harry Percival	Testing	A beginner's introduction to testing and web development with Django. We'll build a simple web app, from scratch, but with full TDD, including functional testing with Selenium and unit testing Django's views, templates, and models. Some familiarity with Python is desirable, but no prior knowledge of Django or testing is assumed.	Novice	TDD with Django, from scratch: a beginner's intro to testing and web development	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
PostgreSQL has a reputation as being complex and hard to manage. It is certainly a powerful, capable database able to handle situations from a developer's laptop up to petabyte-sized installations. But that does not mean that only a special priesthood can operate it; any talented developer is capable of keeping a PostgreSQL installation healthy and happy. We'll go through the tasks that encompass 90% of what you'll have to do with PostgreSQL, from installation, through basic server tuning, routine backups and maintenance tasks, basic disaster recovery, though query analysis and tuning, and tips and tricks to get maximum performance out of PostgreSQL. A special focus will be on Python-based ORMs and their proper usage, such as Django and SQL Alchemy. We'll cover special situations, such as hosting on AWS, embedded/appliance environments, and the things you should never, ever do.	Christophe Pettus	Databases	PostgreSQL has become the default database for most green-field development projects, and is the data storage architecture behind many major Python-based success stories, such as Instagram. Despite a reputation as being complex and fiddly, Postgres is easy to install, administer, maintain, and use... with just a little bit of orientation. This is that orientation.	Novice	PostgreSQL Proficiency for Python People	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
In this talk, I will survey ethical and moral lessons from the general to the specific.  I'll begin with other professions, moving through to software development in general, then the free, libre, and open source software movement where Python has its roots, and finally Python's own history, in particular the CP4E initiative. I will also propose a conceptual framework for the conversation that needs to happen about what our ethical obligations are to society, and finally, my own vision for what those standards should be.	Glyph	Best Practices & Patterns	As more of the world is controlled by software, software developers have an increasing obligation to serve that world well.  Yet, we don't yet have a sense of what makes a good ethical standard.  The fast pace, success, and youth (in both historical and demographic terms) of our industry have given us the sense that such a standard might not be required.  This talk will correct that misconception.	Novice	The Ethical Consequences Of Our Collective Activities	Saturday	2015-04-11 13:55:00	2015-04-11 14:25:00
Let’s program a robot at PyCon!  Not just some dumb robot that runs around the room and bumps into stuff. Let’s program a baby version of one of those big fancy arms you see at a factory. No, really, we can do this, it is not as hard as you think! It turns out one of the most sophisticated robotics frameworks in the world runs on python and it is open source. This talk is a crash course on Robot Operating System (ROS) and how it can be used to build some wicked cool robots for fun and world domination. We’ll cover the libraries that do the fancy math that help your robot to move and figure out where it is, and what it should do. We will also cover the ROS build system which can be a bit scary, and some of the great visualization and debugging tools in ROS.	Katherine Scott	Other	Lots of people want to learn more about robotics but are unsure where to start. Turns out there is a python robotics framework, and it runs some of the most sophisticated robots in the world! It is also open source, well-documented, and has a great community. In this talk we will look at Robot Operating System ROS.	Intermediate	Robots Robots Ra Ra Ra!!!	Friday	2015-04-10 13:40:00	2015-04-10 14:25:00
Aviation has one of the best approaches to safety and accident response in the world - and programming has some of the worst. Blame culture, lack of testing, numerous deadlines and  failing to plan the worst cases mean that software design and runtime problems are a routine thing, rather than a freakish occurrence. As a private pilot, I was thrust into the world of aviation over three years ago, and the difference to software development was immediately obvious - and there are many things we can take away. Learn about:  Why aviation accidents happen, and how the causes relate to software How to start eradicating blame culture and empower junior developers How hard failure is preferable to soft failure How to test your software without breaking the bank Why too much noisy logging is worse than none at all Why ops people are basically doing the same job as pilots  Plus, there'll be some revealing discussion of how aviation works, and some pictures of planes. Who doesn't like those?	Andrew Godwin	Best Practices & Patterns	What can Python-based software teams learn from aviation? Why should software always fail hard? What's wrong with too many error logs? And why are ops people already like pilots? Learn all this, and about planes, too.	Novice	What can programmers learn from pilots?	Friday	2015-04-10 11:30:00	2015-04-10 12:00:00
Requests has over 23 million downloads from PyPI alone and is relied on by open source projects and companies alike but there's no established best practices to testing an application that uses requests. I am a core developer of requests and the author of github3.py. I use requests on an almost daily basis and have developed some simple and sensible ways of testing libraries and applications that use requests. I am also the author of betamax, one of the libraries we'll be discussing in this talk. Why test at all? Testing is generally accepted as a best practice in our industry. The difficulty is in testing anything that talks to the internet. We all know how to test Django apps that talk to a database. We know how to test most other applications we write. Clearly our applications that use requests can benefit from tests as well. What tools exist? There are many tools that already exist to help you test your code that uses requests. Some of the most popular include responses, httpretty, and vcr.py. Betamax's popularity is growing especially given its simplicity. There is a fundamental flaw with both responses and httpretty though: they encourage the user to write fixture data which means that any time the service changes, the user has to fix their fixtures to match the real world data. Tools like vcr.py and betamax relax that constraint by allowing a real interaction to take place, saving it to disk, and then re-using it. At any time, this interaction can be re-recorded to keep the fixture data up-to-date. What responses and httpretty especially excel at is making the user specify, for a given test, what request the user expects the code to make. In the simplest case, this can be done with the wildly popular mock library which has been included in the Python 3 standard library. What patterns emerge? In my experience, the best approach is a combination of integration and unit tests. Using mock to test the calls made to requests help narrow down test failures or real code failures in dependency upgrades or contribution acceptance. Similarly, integration tests can alert you to a potentially harmful change made in requests during an upgrade. Writing unit tests without providing fixture data also forces the developer to write code that is not coupled tightly. This is a pattern we as a community recognize as beneficial and maintainable.	Ian Cordasco	Best Practices & Patterns	A brief and opinionated view of testing applications and libraries that use requests by a core-developer of requests. You will receive an overview of testing with responses, vcr, httpretty, mock, and betamax.	Intermediate	Cutting Off the Internet: Testing Applications that Use Requests	Saturday	2015-04-11 13:55:00	2015-04-11 14:25:00
"It's happened to everyone: you change a line of code or CSS, your tests pass and you do a release, only to discover that something has broken horribly. Perhaps you forgot to test mobile? Perhaps your layout shifted by a pixel and wrapped in ways you didn't want. Or perhaps you shipped some test markup you didn't mean to. Unit tests rarely catch these sorts of errors because they only test the things you can imagine going wrong. They're good for testing things with well-defined inputs and outputs, i.e. functions. Web pages are messier than this. Visual diffs complement unit tests by checking every pixel on the page. If anything changed from the last ""golden image"", the test fails. Visual diffs have become increasingly common for web apps, but they can also provide a layer of safety for client- and server-side modules, from Flask plugins to JavaScript libraries. The goal of this talk is to introduce visual diffs as a tool for testing libraries. I'll walk through the creation of a visual diff test and a set of golden images using dpxdt, then show how they can be used to catch and debug problems. I'll also show how they can be included in version control to create a visual history of your code using image-aware diff tools like git webdiff. Finally, I'll discuss how git webdiff exemplifies the possibilities of replacing traditional GUI apps with Python-based web servers which run on the user's machine."	Daniel Vanderkam	Testing	"Visual diffs are a great way to check for regressions on web sites which may be missed by unit tests. In this talk you'll learn how to run end-to-end tests on your client and server web libraries using a tool called dpxdt. I'll also show how you can combine it with web-based diff tools like ""git webdiff"" to quickly and confidently iterate on web tools."	Novice	Make web development awesome with visual diffing tools	Saturday	2015-04-11 15:15:00	2015-04-11 16:00:00
We've ported Python to run directly on hardware, without an operating system, based on the GRUB2 bootloader, as part of the BIOS Implementation Test Suite (BITS) project (http://biosbits.org).  We're using Python as a testing and exploration environment for hardware, BIOS, ACPI, and UEFI. In this talk, we'll explore the process of porting Python to a new platform, building an embedded Python as part of another project, recreating enough of libc and POSIX to run Python without an OS, extending CPython with Python itself rather than C, binding to platform-specific services using a foreign-function interface, accessing hardware, and rewriting bits of the CPython implementation and standard libraries for additional portability. This talk includes a live demo of bare-metal Python, directly driving hardware.	Josh Triplett	Python Internals	We've ported Python to run directly on hardware, without an OS, as a testing and exploration environment for firmware, ACPI, and UEFI. This talk will explore porting Python to a new platform, embedding Python, recreating enough of libc and POSIX to run Python without an OS, and binding to platform-specific services. Includes live demo of bare-metal Python, directly driving hardware.	Novice	Porting Python to run without an OS	Friday	2015-04-10 17:10:00	2015-04-10 17:40:00
Identity First, we'll look at some common CPython gotchas involving object identity. We'll try to guess the value of various is statements, and then see what the actual value is. Then, we'll discuss why some of these statements evaluate to True and others False, and how object identity differs from equality. We'll discuss some implementation details of CPython, and how they lead to is evaluating differently for integers between -5 and 256 and integers outside that range. Finally, we'll cover some quick practical tips about how to avoid bugs resulting from using the is statement. Mutability Again, we'll look at some common Python gotchas, this time caused by mutability. Then, we'll investigate which common Python objects are mutable and which aren't, which operations mutate Python objects, and what happens when you mutate an object. In the case of mutable default arguments, we'll even see how we can mutate the default argument from outside the function body using some internals that Python exposes to us. We'll end this section by discussing some practical tips on how to avoid bugs due to mutability, how to make real copies, and a common alternative to using mutable default arguments. Scope First we'll see some examples of Python name resolution, and we'll try to guess what object the name is bound to, if any, with some surprising results. After seeing some examples, we'll investigate how the Python interpreter does name resolution, and we'll explore the meaning of the cryptic UnboundLocalError.	Amy Hanlon	Python Core (language, stdlib, etc.)	"Many of us have experienced a ""wat"" in Python - some behavior that totally mystifies us. We'll look at three areas where wats arise - identity, mutability, and scope. For each of these three topics, we'll look at some common surprising behaviors, investigate the cause of the behaviors, and cover some practical tips on how to avoid related bugs."	Novice	Investigating Python Wats	Saturday	2015-04-11 10:50:00	2015-04-11 11:20:00
As a web developer, I find myself being asked to make increasing numbers of data visualizations, interactive infographics, and more. d3.js is great, as are many other js toolkits that are out there. But if I can write more Python and less JavaScript... well, that makes me happy! Bokeh is a new Python library for interactive visualization. Its origins are in the data science community, but it has a lot to offer web developers. In this talk I'll discuss using Bokeh with a web framework (in this case, Django):  I will walk through building an interactive visualizations in Bokeh to display your data How to unit test your visualization How to display your plot on the web and within your templates, including a number of pitfalls I have encountered.  I will not be covering real-time or high-volume analytics, or any statistical processing. This is an introduction to Bokeh's core, focused on the needs of an average web developer.	Sarah Bird	Web Frameworks	Interactive data visualization libraries are mostly a JavaScript stronghold. The new Python library, Bokeh, provides a simple, clean way to make more shiny things. Although it comes from the data science community, it has a lot to offer web developers. For a visualization you might have built in d3.js, I'll show how to build it in Bokeh, how to test it, and how to hook it into your web app.	Novice	Interactive data for the web - Bokeh for web developers	Sunday	2015-04-12 13:10:00	2015-04-12 13:40:00
If you aren’t wowed by Python’s super() builtin, chances are you don’t really know what it is capable of doing or how to use it effectively. There has been a great deal of misunderstanding about super(). This talk seeks to improve on the situation by:  providing practical use cases giving a clear mental model of how it works showing the tradecraft for getting it to work every time concrete advice for building classes that use super() favoring real examples over abstract ABCD diamond diagrams. 	Raymond Hettinger	Best Practices & Patterns	"Python's super() is well-designed and powerful, but it can be tricky to use if you don't know all the moves.

This talk offers clear, practical advice with real-world use cases on how to use super() effectively and not get tripped-up by common mistakes."	Intermediate	Super considered super!	Friday	2015-04-10 15:15:00	2015-04-10 16:00:00
As technical community managers we are faced with a unique set of challenges. Like most FOSS community members, we're often volunteers, but the work we do in moderating mailing lists, planning events, fielding project feedback and contributions, and being the public face of our communities can take an additional emotional toll. We do it because we love our communities, but we also are often guilty of neglecting our own very real needs in order to serve those communities. We end up feeling guilty, run down, inadequate, and ultimately burnt out. Does this sound like you? Even if you don't do community management work, you might have run into some of the same frustrations. In this talk I'll share with you my own experiences in building and managing different communities.  Through my own lessons learned, I'll strive to help you think about ways to:  Recognize and handle burnout Understand the causes of burnout and how they apply to your FOSS work Build a vocabulary to talk and think about the challenges you face Identify coping strategies that make sense for your unique situation Avoid burnout next time around 	Kathleen Danielson	Community	As technical community managers we are faced with a unique set of challenges. We do it because we love our communities, but we also are often guilty of neglecting our own very real needs in order to serve those communities. We end up feeling guilty, run down, inadequate, and ultimately burnt out.	Novice	Avoiding Burnout, and other essentials of Open Source Self-Care	Saturday	2015-04-11 17:10:00	2015-04-11 17:40:00
Ever wondered what all the hubbub was about with Salt or Ansible? Ever wonder how Ansible is different from Fabric or who would win in a grudge match between Thomas and Michael (respective creators of SaltStack and Ansible)? In this tutorial we'll explore three popular tools for remote execution and automation: Fabric, SaltStack, and Ansible. We'll see how they compare to, contrast with, and compliment one another.	G. Clifford Williams	Systems Administration	"Epic, knock down, drag-out, death match of python automation tools. Ok, not really.

This class will take an in depth look at three automation, orchestration, and remote execution frameworks written in Python."	Novice	Fabric, SaltStack, and Ansible: DevOps'ing with Python	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
Machine learning forms the core of many intelligent services we use today, including language translation, web search, movie recommendation, and spam detection. Python's ecosystem provides a high quality array of tools for developing insights on these use cases and applying machine learning in production. In this tutorial, we will provide a hands-on introduction to the concepts of machine learning and the process of applying these concepts in a competition setting. We'll start out with an overview of machine learning applications and how computers can learn from data. Then, we'll look at algorithms and methodologies that have been demonstrated to work well in a wide variety of applications, and what makes these algorithms tick. For the bulk of the tutorial, we'll focus on a live Kaggle competition. We'll load the data into iPython notebook for interactive exploration and visualization, and use this to gain a basic understanding of what's in the data. From there, we'll extract features and train a model using scikit-learn. This will bring us to our first Kaggle submission. Next, we'll switch out of iPython notebook and start structuring the code for repeatability, using git for version control and Make for an explicit dependency graph. We'll learn how to structure the problem for offline evaluation and then use scikit-learn's clean model API's to train many models simultaneously and perform feature selection and hyperparameter optimization. At this point, we'll provide suggestions for how to further improve on the problem and then finish with an hour-long lab, with tutorial participants working individually or in groups to improve their methodologies and getting advice as needed. By the end of this tutorial, participants will have a basic understanding of how to identify problems where machine learning can add value, along with how to use machine learning and the Python ecosystem to address these problems. They will be able to apply these techniques to their work, hobbies, Kaggle competitions, and research.	Ben Hamner	Science	This tutorial will offer an introduction machine learning and how to apply it to a Kaggle competition. We will cover methodologies that have worked well across a diverse set of problems, and then work on a current Kaggle competition together using iPython notebook and scikit-learn. We will cover concepts including feature extraction, feature selection, model evaluation, and data visualization.	Intermediate	Winning Machine Learning Competitions With Scikit-Learn	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
This talk will consist of three main chunks:   Background: The whats, whys, and hows of internationalization (i18n) and localization (l10n). We’ll walk through the whole process of marking and scraping strings for translation, as well as how translated strings are served up. Our goal here is to get a good picture of what really happens to your l10n’ed strings at runtime and discuss a few common pitfalls.   i18n tools: What does Django natively provide to help us scrape and serve up strings in Python files and Django templates? (Simple, easy to use scripts (•ω•)) How can we tackle other types of files, such as Mako or Underscore templates, or Javascript files? (Complex, easy to use scripts (｡◕‿‿◕｡))   The eye of the translator, the thrill of the no-context fight: Now that we’ve got the basics down, let’s turn our attention to how our strings actually get translated. Can an open-source project obtain translations for free? (Yes!) What is the job of translator really like? (Like this: (╯°□°）╯︵ ┻━┻) What can we as developers do to both ease their burden and get more accurate translations? (I’ll show you how to ┬──┬ ノ( ゜-゜ノ))  	Sarina Canelake	Best Practices & Patterns	Have you heard about internationalization (i18n) and wondered what it meant? Perhaps your project already has i18n of its strings but you have a nagging feeling you could be doing it better. This talk will walk through the basics of i18n’ing a Django project (but the principles apply to any project!), and how to make the process of localization (l10n) go more smoothly.	Novice	I18N: World Domination the Easy Way	Friday	2015-04-10 17:10:00	2015-04-10 17:40:00
Docker is an open source, lightweight, virtualized environment for portable applications. With all the buzz it has attracted, it can be hard to figure out exactly what Docker is and what it can do for you. This talk will cover the fundamentals of Docker, why it’s making waves, and how it might be a useful addition to your platform. Specifically, this talk will cover:  What Docker is (and what it isn’t) compared to other application deployment techniques The fundamental technical features that distinguish Docker from traditional Virtual Machines (VMs) or other containerization techniques The basic concepts of Docker (e.g. containers vs. images, Docker Engine vs. Docker Hub) Some practical applications of Docker and how it is used in production A sample Docker development workflow using a Flask app A little Docker history and some predictions about how Docker could affect computing in the future Things to consider when evaluating Docker for use in your organization  The target audience for this talk is developers with some experience deploying and managing applications who are curious about Docker and how it could benefit their work. Attendees new to Python are welcome, but they will benefit most from this talk if they also have experience deploying software applications in some other language.	Andrew T. Baker	Systems Administration	Docker was one of last year’s most talked about open source projects - but what is it? And what does it mean for deploying applications? This talk will explain what Docker is and where it fits in with other deployment techniques. Attendees will learn the fundamentals of Docker, see some practical examples of how Docker is used, and consider if Docker could be a useful addition to their platform.	Novice	Demystifying Docker	Saturday	2015-04-11 12:10:00	2015-04-11 12:40:00
Real-time webapps may be all the rage with NodeJS, but you can write them in Python too. Underneath a real-time webapp lies a technology called WebSockets, part of the HTML 5 spec. This talk takes a deep dive into WebSockets and how this TCP-based protocol works on the client- and server-side, using Python networking tools to see what actually goes over the wire. We'll also talk about protocol details you're sure to run into deploying a WebSockets app in production, like connection upgrading and gracefully falling back to older technologies when clients don't support WebSockets. All this networking and protocol talk may sound dry, but don't worry, I'll make it fun. :)	Christine Spang	Web Frameworks	"HTML5 WebSockets power the real-time web. Come take a deep dive into how they
work, from the big picture down to what goes over the wire, including insight
into the performance benefits of the protocol, via a real-world example of how
WebSockets are implemented client- and server-side in Python."	Intermediate	WebSockets from the Wire Up	Sunday	2015-04-12 13:50:00	2015-04-12 14:20:00
In this tutorial, I will show you how you can use data to construct networks for data analysis.  The goal is to demystify graph analytics and mining, and make it accessible to the general programmer. Starting with understanding a toy data set as an anchor, we will go through:  graph basics (nodes + edges, list and matrix representations),  modelling problems as graphs, preprocessing data using Pandas, importing data using NetworkX, how to compute basic statistics of the network generating visualizations using matplotlib, finding hubs, paths and clusters in the data, (if time permits) random graphs for statistical inference  IPython notebooks and data files will be distributed beforehand on Github to facilitate code distribution. As good pedagogical practice, we will have lots of guided hands-on time, and about 30 min to 1 hour of unstructured “free hacking time” to explore a bike sharing data set (with suggested questions) in small groups of your choice of size. You will also share your IPython notebooks via Github. After the hacking time, we will showcase a select number of analyses.	Eric Ma	Science	Have you ever wondered about how those data scientists at Facebook and LinkedIn make friend recommendations? Or how epidemiologists track down patient zero in an outbreak? If so, then this tutorial is for you. Here, we will explore a bike sharing data set as a way to understand the kinds of problems that can be solved using graph analytics.	Intermediate	Practical Graph/Network Analysis Made Simple	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
TLS is the most widely used protocol for securing TCP connections. We start with the history of TLS and an overview of its features. The core of the talk is devoted to describing how TLS provides two fundamental security properties: confidentiality and authentication. We discuss the use of X.509 certificates as well as the numerous ciphers and cryptographic algorithms TLS supports. Along the way, we see how TLS support in the Python standard library has improved dramatically in the last year and how to properly use it.	Benjamin Peterson	Security	TLS is the industry standard for secure networking. This talk will give an overview of the TLS protocol and demonstrate how to create secure connections with the standard library's ssl module.	Intermediate	A Dive into TLS	Friday	2015-04-10 12:10:00	2015-04-10 12:40:00
Machine learning is a huge part of modern computing - from Facebook auto-tagging, spam rejection, and Google searches to robotic cars, predictive healthcare, and phones that can warn you about traffic jams before leaving work, machine learning is everywhere. These tools enhance our lives, and understanding what machine learning can (and can't) do is crucial to modern software development. Thanks to the amazing Python ecosystem, it is not necessary to have deep knowledge of the mathematical techniques and statistics behind machine learning in order to use these algorithms in your daily work or hobby projects. Libraries like pandas, scikit-learn, gensim, and Theano help developers build projects that were previously impossible, and these applications empower our users and can make fundamental improvements to daily life. This talk will show you the why, what, and how of machine learning in Python.	Kyle Kastner	Education	Machine learning is a crucial part of modern software development. Libraries like pandas, scikit-learn, gensim, and Theano help developers build projects that were previously impossible, and these applications empower our users and can make fundamental improvements in daily life. This talk will show you the why, what, and how of machine learning in Python.	Intermediate	Machine Learning 101	Friday	2015-04-10 10:50:00	2015-04-10 11:20:00
Beginning programmers: welcome to PyCon! Jumpstart your Python and programming careers with this 3-hour interactive tutorial. By the end, you'll have hands-on exposure to many core programming concepts, be able to write useful Python programs, and have a roadmap for continuing to learn and practice programming in Python. This tutorial assumes no prior programming experience. We'll cover:  Python as a calculator Basic data types Interactive programs: input and output Making choices: booleans and flow control Lists and iteration Functions  We'll also practice writing Python scripts, see demos of cool Python applications, and take a quick tour of popular Python libraries. By the end of this tutorial, you'll have the background and context to learn a lot more as you go through the rest of PyCon. You'll also be in great shape to continue learning Python through longer-form resources and start working on your own Python projects.	Dana Bauer	Python Core (language, stdlib, etc.)	Beginning programmers: welcome to PyCon! Jumpstart your Python and programming careers with this 3-hour interactive tutorial. By the end, you'll have hands-on exposure to many core programming concepts, be able to write useful Python programs, and have a roadmap for continuing to learn and practice programming in Python. This class assumes no prior programming experience.	Novice	A hands-on introduction to Python for beginning programmers	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
Every web framework out there comes with an ORM, but should you actually use it? An ORM makes it super easy to get up and running really quickly, but maintainers of growing database-backed applications almost always run into performance problems down the road. When this happens, what do you do? This talk's goal is to show you what actually happens under the hood when you make a query in an ORM like SQLAlchemy, and, by giving you the power to de-mask which SQL queries are being executed, build your intuition for when to use caution with an ORM. Sometimes, like in schema migrations, you may even want to just hand-craft the raw SQL yourself. This talk is based off of real-world examples learned while building Inbox, which is available free and open source, so you'll be able to take a look at the results of these lessons and how the codebase has evolved to become more performant.	Christine Spang	Databases	Database ORMs make it really convenient to pythonically query a database, but it's difficult to decide when to use them and when not to---and what the alternatives are. In this talk you'll learn strategies for deciding when and where to use an ORM, when to be cautious, and how to tell that you're doing the right thing, drawn from real-world lessons learned building the Inbox email platform.	Intermediate	To ORM or not to ORM	Saturday	2015-04-11 14:35:00	2015-04-11 15:05:00
"Everyone who has to deal with data eventually has to deal with messy data. This task often takes over 50% of the effort yet is often billed as ""not the meat of the work"" and no one gets trained in it. Government data consumers, social scientists, other scientists, and even you, dear data consumer, might like this talk! You'll learn how to tackle day to day data cleaning. Spotting issues with data, dealing with missing data and merging datasets are among the topics. I'll mention the deep, dark parts of pandas that help specifically with different types of cleaning, go over some lesser known but neat libraries and tools like Sunlight Labs' jellyfish, messytables, chardet, etc. I'll mention some thoughts on data collection, and finally go over a demo of cleaning a real life dataset!"	Mali Akmanalp	Python Libraries	Have you ever viscerally hated a dataset? Do you want to just get data cleaning out of the way? Are you always left wondering how it consumes most of your time? Whether you work in the sciences, work with government data or scrape websites, data cleaning is a necessary evil. We'll share our woes and check out state of the art in day to day data cleaning tools and strategies.	Intermediate	Other people's messy data (and how not to hate it!)	Saturday	2015-04-11 13:55:00	2015-04-11 14:25:00
Full WSGI web application deployments involve a complicated collection of software tools that can be difficult for new developers to wrap their heads around. This talk is based on content laid out on the Full Stack Python which allows readers to navigate content in the order they choose. With this talk the audience similarly chooses the topics based on real-time text message and email voting. We'll start with an overview of a typical WSGI deployment shown below.  After explaining the components of web deployments and how they fit together, we will dive into five advanced deployment topics with 5-7 minutes of content per section. These topics include  hardening your web application against hackers  improving performance as web traffic scales up tracking bugs and aggregating issues with logging analyzing web traffic to better understand your users scaling a development team to produce more features implementing caching to minimize database access automating deployments with configuration management tools handling jobs asynchronously with task queues sending email via SMTP and external web APIs  All topics above are prepared for this talk but only the ones chosen based on the audience's selections during the decision points screens will be covered. The decision points where the audience texts in will look something like the following screenshot. We will also incorporate voting by email address so those without cell phone service can also join in on choosing the path through the story. 	Matt Makai,Kate Heddleston	Web Frameworks	From servers and proxies to configuration management, the Web Server Gateway Interface (WSGI) deployment ecosystem is complicated for new developers. This choose your own adventure talk contains decision points for the audience to choose topics via text and email votes. Each choice leads down a separate path to explain different confusing WSGI subjects. Bring your phone or laptop to participate!	Intermediate	Choose Your Own WSGI Deployment Adventure	Saturday	2015-04-11 16:15:00	2015-04-11 17:00:00
This tutorial provides the big-picture view the documentation lacks. Though you will get your hands on many of ES's features, we won't waste your time slogging page by page through the reference manual—you can look up specific corner cases any time. Instead, we will give you the mental framework to organize—and even predict—the specifics. Without assuming you know anything about Lucene, we will pull back the curtain to explore the data structures used for indexing, the algorithms that make faceting so fast, and the tradeoffs involved in replication and sharding. From these fundamentals, you will be able to deduce how to make your own use cases efficient. You will also see how far ES can be stretched, applying some clever Python preprocessing to do things like trigram-accelerated regex matching. Finally, you will learn to avoid the mistakes we made, both in design and deployment, so you can build a stable cluster that needs no babysitting.	Erik Rose	Databases	Elasticsearch provides a powerful combination of clustered full-text search, synonyms, faceting, and geographic math, but there's a big gap between its documentation and real life. We'll work through hands-on examples, tell war stories yielding hard-won lessons, and show what happens behind the scenes, equipping you to slither smoothly into using Elasticsearch in your own projects.	Intermediate	Slithering Into Elasticsearch	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
Social app development challenges us to code for users’ personal world. Users are giving push-back to ill-fitted assumptions about their own identity — name, gender, sexual orientation, important relationships, and many other attributes that are individually meaningful. How can we balance users’ realities with an app’s business requirements? Facebook, Google+, and others are struggling with these questions. Resilient approaches arise from an app’s own foundation. Discover how our earliest choices influence codebase, UX, and development itself. Learn how we can use that knowledge to both inspire the people who use our apps, and to generate the data that we need as developers.	Carina C. Zona	Best Practices & Patterns	Development challenges us to code for users’ personal world. Users give push-back to ill-fitted assumptions about their own name, gender, sexual orientation, important relationships, & other attributes that are individually meaningful. We'll explore how to develop software that brings real world into focus & that allows individuals to authentically reflect their personhood & physical world.	Novice	Schemas for the Real World	Saturday	2015-04-11 15:15:00	2015-04-11 16:00:00
Virtually all software systems have security issues. They affect teams of every experience level and systems at every scale, and their effects can be anywhere from minute to disastrous. After all: we know that in most fields, striving for zero defects is simply unrealistic; if you accept that some of those defects affect security, striving for zero security issues is unrealistic as well. Like all other bugs, saying that they are unavoidable doesn't absolve us from responsibility. We still ought to limit them, both in number and in impact. While we have many tools for limiting generic defects, we don't have much in terms of a rigorous approach to handling security problems. This is partially because the tools we have don't necessarily apply.  Additionally, as an industry, we have historically not given information security the attention it deserves. This is the case from many different angles, including engineering, business, and education. As more and more serious breaches of security become publicly visible, information security is increasingly on everyone's mind. Put together, this means that while we ought to be taking these problems seriously, we systematically don't -- and, even when we do, we're ill-equipped to do so. This talk deals with that problem.	lvh	Security	How do you build secure software? Why do we see bad security track records in projects that otherwise seem to tick all the right engineering boxes? Why is communicating about security issues so painful? More importantly: how can we do all of these things better?	Novice	Building secure systems	Friday	2015-04-10 10:50:00	2015-04-10 11:20:00
Knowing that your application is up and running is great.  However in order to make informed decisions about the future, you also need to know in what state your application currently is and how its state is developing over time. This talk combines two topics that are usually discussed separately. However I do believe that they have a lot of overlap and ultimately a similar goal: giving you vital insights about your system in production. We'll have a look at their commonalities, differences, popular tools, and how to apply everything in your own systems while avoiding some common pitfalls.	Hynek Schlawack	Best Practices & Patterns	Your Python server applications are running but you’re wondering what they are doing?  Your only clue about their current state is the server load?  Let’s have stroll through the landscape of logging and metrics so you’ll find the perfect fit for your use cases!	Intermediate	Beyond grep: Practical Logging and Metrics	Sunday	2015-04-12 13:10:00	2015-04-12 13:40:00
"After attending this tutorial, attendees will gain general knowledge, being able to:   Explain the difference between cross-site scripting and cross-site request forgery, and understand at least one way abuse each.   Describe the use of cookies in web applications and how they relate to security.   Identify authorization bugs in web applications, and name programming patterns that avoid authorization bugs.   Understand how to think like a attacker, by practicing being one.   They will be able to perform and explain specific attacks as well, such as:   Taking advantage of subdomains to steal cookies, and how to use a stolen cookie to impersonate another user.   Abusing file uploads to defeat security protections within a web app.   Abusing a Django SECRET_KEY to steal a fellow user's account.   Leveraging the ""pickle"" module to run chosen code in the context of someone else's web app.   Attendees will leave the tutorial with an appreciation of the importance of security and practical experience that enables further study."	Asheesh Laroia,Jacky Chang,Nicole Zuckerman	Security	"Web application security can be an intimidating discipline, yet it can be of supreme importance for the people who use the things we build.

In this tutorial, you'll learn about essential topics in web security, and you will gain hands-on practice identifying and leveraging vulnerabilities in a Python-based web app. For each issue, we will cover how your code can stay on the side of safety."	Intermediate	Getting comfortable with web security: A hands-on session	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Spark is a distributed computing (big data) framework, considered by many as the successor to Hadoop. You can write Spark programs in Java, Scala or Python. Spark uses a functional approach, similar to Hadoop’s Map-Reduce.  In this tutorial we will cover the basics of writing spark programs in python (initially from the pyspark shell, later with independent applications). We will also discuss some of the theory behind spark, and some performance considerations when using spark in a cluster.	Orlando Karam	Other	In this tutorial we will cover the basics of writing spark programs in python (initially from the pyspark shell, later with independent applications). We will also discuss some of the theory behind spark, and some performance considerations when using spark in a cluster.	Intermediate	Introduction to Spark with python	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
"Are you considering incorporating React.js into your existing Python web application?  React.js is an open-sourced library by Facebook, and described as ""A JavaScript library for building user interfaces."" In my talk I will dive into React.js and explain how React completely changes the front-end development.  A few points I will cover include:  how React's Virtual DOM makes UI rendering fast how to think of UI as composable React components instead of templates how React's one-way data flow makes state management simpler  Then, I will show how to make a simple single page application with Python back-end and React.js front-end. Hopefully, I can demonstrate why using React.js can help you write a more maintainable front-end code."	Moon Limb	Web Frameworks	Are you a Python web developer who is curious in learning about React.js?  I will demonstrate how to incorporate React.js into an existing Python web application. Along the way, I will explain some cool features of React.js, and how using it can help you write more maintainable front-end code.	Intermediate	Seasoning Python Web Applications with React.js	Sunday	2015-04-12 14:30:00	2015-04-12 15:00:00
This talk explains the basics of what happens when you start a Python interpreter from a command prompt. It covers the following topics:  What a process ID is. What it means to forking a subprocess, and what environment variables are. How $PATH affects what your shell does. The underlying meaning of shell quoting. The difference between three ways to exit Python: exit(), ^C, and ^D. 	Philip James,Asheesh Laroia	Systems Administration	"This talk discusses how the Python interpreter starts, from the perspective of the operating system (OS). Together, we will see the ins & outs of processes: fork(), exec(), stdin, and stdout.

It focuses on OS concepts and requires no background knowledge, using analogies to Python data structures. (The talk does not discuss Python’s own initialization, such as site.py or global variables.)"	Intermediate	Type python, press enter. What happens?	Saturday	2015-04-11 11:30:00	2015-04-11 12:00:00
Docker is an open source, lightweight, virtualized environment for portable applications. With all the buzz it has attracted, it can be hard to figure out exactly what Docker is and what it can do for you. This tutorial will teach you the fundamentals of Docker, why it’s making waves, and how it might be a useful addition to your platform. In this session you will:  Learn the basics of working with Docker containers and images Create your own Docker images Learn how to “dockerize” a sample Flask application Publish to the Docker Hub (the GitHub of Docker) Use Fig to manage multiple Docker containers at once Learn about deploying to one of the new Docker-specific cloud hosting services  Students will spend most of this session getting their hands dirty in a series of exercises, which are introduced with some brief presentations. The exercises will be mostly self-paced, though students are encouraged to seek help from the instructor or their neighbors if they need it. The session is loosely based off O’Reilly’s “Introduction to Docker” video tutorial. A Vagrantfile and Ansible playbook will be available to help students work locally. Fully provisioned cloud servers will be provided for students who don’t want to set up local development environments.	Andrew T. Baker	Systems Administration	Docker was one of last year’s most talked about open source projects - but what is it? And what does it mean for deploying applications? This tutorial will explain what Docker is and where it fits in with other deployment and configuration management tools. Students will then learn the basics of working with Docker containers, how to “dockerize” their Python apps, and some emerging best practices.	Novice	Docker 101: Introduction to Docker	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
We often write code with bugs. They're usually shallow, simple things, but sometimes they're incredibly complex and take hours (or more) of our time to pinpoint their causes. This talk explores these types of bugs, what type of code or environmental factors makes them so hard to track down. What tooling can make it easier to expose their cause, and what techniques can we use to better model these problems and increase our understanding earlier in the process. Using real world examples of hard problems, I'll show how these techniques have debugged problems such as:  posix_spawn calls mysteriously failing to start a new process Every few minutes a giant request spike to a website A failure to make an HTTPS request to some websites 	Alex Gaynor	Best Practices & Patterns	Sometimes your programs have bugs. Often they're shallow things, simple AttributeErrors or TypeErrors. Sometimes they're large, complex, and nearly impossible to debug. This talk explores techniques for figuring these out.	Intermediate	Techniques for Debugging Hard Problems	Saturday	2015-04-11 16:30:00	2015-04-11 17:00:00
"This is an introduction to the (relatively) new asyncio module that arrived in the standard library of Python 3.4. The documentation states that asyncio,  ""...provides infrastructure for writing single-threaded concurrent code using coroutines, multiplexing I/O access over sockets and other resources, running network clients and servers, and other related primitives.""   While we probably all understand much of the theoretical terminology in this definition, I intend to explore and illustrate what this means in practice (with examples from a real-world networked application I have written using asyncio). To this end, I will assume no previous knowledge of asyncio and present:  A description of the problem asyncio helps to solve; An introduction to core asyncio concepts such as the event loop, co-routines, futures and network abstractions; A description of how such concepts fit together; The story of how I rewrote my distributed hash table library with asyncio (from Twisted); Examples of real-world asyncio development: unit-testing, what's easy, what's hard, when shouldn't you use asyncio? Where to find out more.  By the end of this introductory talk I hope you will have a desire to learn more about asyncio and perhaps give it a try in your own projects."	Nicholas Tollervey	Python Libraries	"This talk introduces the asyncio module. I'll cover what it's for, how it works and describe how I used it to write a real-world networked application (a distributed hash table).
We'll explore the event loop, co-routines, futures and networking with examples from my code.
This won't be an exhaustive exposition. Rather, attendees will grasp enough of asyncio to continue with their own studies."	Novice	"Lessons learned with asyncio (""Look ma, I wrote a distributed hash table!"")"	Saturday	2015-04-11 17:10:00	2015-04-11 17:40:00
HTTP is the most successful application-layer network protocol of all time. The vast majority of network traffic today is either transmitted using HTTP or by protocols associated with it. It is ubiquitous: so much so that the 'world wide web', the network of systems that speak HTTP, is for many people totally synonymous with the Internet. In part because of its success, HTTP is also quite old. The current revision, HTTP/1.1, was originally standardised in 1999. This was an era in computing quite unlike the current one. For perspective, Napster was originally released in 1999, and Google was only one year old. The web was totally unlike what we have now: pages were small and carried relatively little non-textual data, computers were relatively weak, and the mobile data plan was unheard of. HTTP/1.1 was designed for a world that no longer exists. We need an update. HTTP/2: A New Era Into this void stepped the Internet Engineering Task Force. In 2012, the HTTPBis Working Group of the IETF, tasked with ensuring that HTTP continues to grow, began discussing a new version of the protocol. Now, three years later, HTTP/2 is the end result. It's a protocol with a unique position in the history of computer networks. Its goal: to bring the web into the 21st century, without breaking anything that already worked. These two competing goals make HTTP/2 an intriguing entry in the catalogue of network protocols. The final standard was delivered early in 2015, and with the delivery of this standard will come a flurry of activity as web developers and consumers get used to the new tool driving the web. Work will begin on subsidiary standards like WSGI and WebSockets, and developers will start finding new ways to push the web ever-faster. It's an exciting time. This Talk This talk will cover HTTP/2 at a high level. We'll talk about how we got here. We'll talk about the problems of HTTP/1.1, and how HTTP/2 aims to address them. We'll talk about the ways in which HTTP/2 is imperfect, and how those imperfections came to be. And finally, we'll talk about how you can get started using HTTP/2 with your Python code, giving you a head start on this exciting new protocol.	Cory Benfield	Other	The internet has spoken, HTTP is to get its first serious update in 15 years. In this talk we'll discuss what HTTP/2 is, why it's happening, and how it's going to affect you and everyone you love. We'll briefly talk about how you can get started with HTTP/2, and some interesting projects associated with it, including Hyper, the first Python HTTP/2 library.	Novice	Hyperactive: HTTP/2 and Python	Friday	2015-04-10 12:10:00	2015-04-10 12:40:00
Porting Python 2 code to work with Python 2 & 3 without a constant 2to3 translation step is not hard anymore. With tools such as python-modernize or futurize, the mundane details are taken care of for you (e.g. syntactic changes). That leaves only high-level API choices as the roadblock to porting and a couple of gotchas to look out for (e.g. what APIs should accept bytes vs. strings). And with 2to3 out of the picture it makes development much faster. Toss in linting tools such as Pylint and you can make sure that once you make your changes that you don't accidentally regress. Add constant integration testing through tools like Tox once you can use Python 3 and your Python 3 support will become negligible to maintain. There is even tools now like caniusepython3 which help let you know when your project's dependencies have made the switch.	Brett Cannon	Best Practices & Patterns	You know Python 3 is an improvement over Python 2 and you want to use it. Unfortunately you have legacy Python 2 source code that needs to stay compatible. But don't fret! This talk will show you that you can make your code be Python 2/3 source-compatible using various tools to pick up the nitty-gritty work and help modernize your Python code to newer Python 2 practices.	Intermediate	How to make your code Python 2/3 compatible	Friday	2015-04-10 13:55:00	2015-04-10 14:25:00
"When faced with a new or complicated code base, ""Finding your groove"" can feel like the sound of fingernails on a chalkboard or a toddler banging on pots and pans. It's often frustrating and headache inducing to hear jargon filled talks, like generator blah blah stdlib blah venv blah calloc blah Rietveld blah rebase blah deprecate. Can't I just bury my head in a quilt of old PyCon t-shirts and hibernate until CPython 42.0 is released?  The famous bridge keeper scene from Monty Python helps guide us: What is your name?     Sir Doc-a-lot of Test-a-lot  What music do you like?     Jazz  What is your quest?     To find the holy CPython commit.  Seriously, the path over the bridge to contributing and productivity in CPython can be crossed.  Yes, there's a way to make sense of CPython with confidence and productivity. How? Let jazz music guide you to:  commit jump into it find a rhythm improvise celebrate  This talk will help break down the complex and sometimes cloudy process of contributing to CPython (or your favorite codebase) by helping you:  demystify the CPython contribution process; find quality resources and help; identify a suitable issue to work on; master the non-linear contribution process; succeed as a contributor.  You will leave this talk with concrete resources to get started, to consult as your experience grows, and to pass along to others in your travels."	Carol Willing	Python Core (language, stdlib, etc.)	Do you hear a jumble of jargony noise when reading Python mailing lists? Do you silently edit your dotfiles and playlists to avoid asking questions on IRC? Come see how Jazz can help you understand and contribute to Python. While both seem vast and complex, they build on simple concepts. By mixing art, knowledge, and improv, you can find your CPython contribution groove and enjoy cool cats' music.	Intermediate	Finding Your Groove: Contributing to CPython and Beyond	Saturday	2015-04-11 11:30:00	2015-04-11 12:00:00
Shakespeare is the greatest writer in the English language. But what makes him perfect for an illustration of what Python can do with text? Simple: he’s already been extensively marked up in XML, so we can jump right into the good stuff. While we’ll be mostly using Shakespeare in this talk, we’ll make sure to see how our techniques can easily apply to other sorts of texts, like tweets or newspaper articles. After a brief conversation about the usefulness of metadata, the talk will concern itself with two main sections: classification and informational entropy. First, we’ll explore how to find distinguishing features between kinds of texts and to use this data to classify other texts. For entropy--which is roughly a measure of randomness--we’ll look at unexpected, and therefore information-rich, parts of Shakespeare’s works.	Adam Palay	Best Practices & Patterns	This talk will give an introduction to text analysis with Python by asking some questions about Shakespeare and discussing the quantitative methods that will go in to answering them. While we’ll use Shakespeare to illustrate our methodologies, we’ll also discuss how they can be ported over into more 21st century texts, like tweets or New York Times articles.	Novice	"""Words, words, words"": Reading Shakespeare with Python"	Friday	2015-04-10 11:30:00	2015-04-10 12:00:00
"What exactly are weak references anyway, especially when compared to normal (hard) references? And do they really matter for the code we write? That second question is easy to answer. You need to think about weak references if you are writing the following and want to avoid resource leaks:   Objects having reference cycles on CPython, such as a parent   referring to its children, and the child to its parent.   Caches and lookup tables, which often come up in Python   metaprogramming. Using weak references for this scenario may be   applicable, regardless of the Python implementation. For example,   you might want to track the membership of all objects for a given   class. If you only have hard references, this isn't possible without   causing memory leaks.   Now maybe someone has already done this hard coding work, but it's best to know these scenarios to avoid resource leak bugs in the framework, module, or recipe you might be using. Especially in production! But first, what exactly are weak references? Although weak references were initially proposed in PEP 205 and implemented in Python 2.1 (released April 2001), they are still not widely known. So it helps to try out some examples to build our intuition. First, let's import WeakSet. Many uses of weak references are with respect to the collection provided by the weakref module: from weakref import WeakSet  Define a class MyStr like so: MyStr(str):     pass  Next, let's construct a weak set and add an element to it. We then list the set: s = WeakSet() s.add(MyStr('foo')) list(s)  And most likely we will see that it is empty - we get []. Or at the very least after a garbage collection with gc.collect(). With a bit of thought, we realize that nothing was holding on to the instance MyStr(""foo"") - the point of a weak reference, including collections that maintain only a weak reference to their contents like WeakSet, is that only strong references keep objects from being collected. We can see this by adding a strong reference: a = MyStr('fum') s.add(a) list(s)  This returns ['fum']  We now have a variable a in our global namespace that's strongly referencing this value. Of course if we delete this name, we might expect the value to disappear, as it in fact is guaranteed to do, again at least after a garbage collection: del a list(s)  probably still returns ['fum']  But after a collection gc.collect() list(s)  the resulting list is empty: []  So now we have some understanding of the behavior, but why would this sort of thing even be useful? Perhaps the most important thing to know is that once we master the mechanics, with minimal fuss and just a few lines of code we can readily apply to the problems they can solve. In particular this means supporting caching/lookup tables without introducing memory/resource leaks, as well as reference cycle elimination on CPython. Django uses weak references in the implementation of its signal mechanism:  Django includes a “signal dispatcher” which helps allow decoupled applications get notified when actions occur elsewhere in the framework. In a nutshell, signals allow certain senders to notify a set of receivers that some action has taken place. They’re especially useful when many pieces of code may be interested in the same events.  Such decoupling is a perfect usage of weak references. Although it is certainly possible to compute this coupling between senders and receivers on the fly, it's expensive to do, so caching is preferred. In Django's case, because the caching is implemented with a WeakKeyDictionary, cleanup is straightforward. But there's at least one other usage to consider. Although CPython does support the collection of reference cycles, there are important caveats:   Such cycles can be only be collected upon the stop-the-world GC    collection. Without calling gc.collect directly, such collections    are run per the decision criteria in the gc.set_threshold    function, which has been further enhanced since 2.5 to support    generations. Suffice to say, it doesn't occur necessarily when you    would need it to, and certainly not on the basis of running out of    memory, or on a periodic basis.   Using __del__ with such cycles creates uncollectable garbage.   As a consequence, when creating numerous parent-child relationships, as seen in xml.sax.expatreader or previous/next links, as seen in OrderedDict, it is important to use weak references for one side of the relationship, or else it's very easy to see problems arise. In particular, OrderedDict uses weakref.proxy for previous links. By doing so, using code automatically chases the extra level of indirection to the previous object; but the next link ensures that a hard reference is present, so the object doesn't disappear."	Jim Baker	Best Practices & Patterns	Working with weak references should not just be for Python wizards. Whether you have a cache, memoizing a function, tracking objects, or various other bookkeeping needs, you definitely do not want code leaking memory or resources. In this talk, we will look at illuminating examples drawn from a variety of sources on how to use weak references to prevent such bugs.	Intermediate	A Winning Strategy with The Weakest Link: how to use weak references to make your code more robust	Saturday	2015-04-11 17:10:00	2015-04-11 17:40:00
Are you interested in open source, but having difficulty getting started?  Do you maintain a project that can’t seem to find new contributors? This talk will cover some of the most common “failure modes” of open source contributing, from the technical to the interpersonal.  Drawing from my experience organizing and running dozens of newcomer workshops, and using examples from various open source python projects, I’ll show you:  How to make good matches between newcomers and projects How to create and identify good first tasks for new contributors How to ease the pain of setting up development environments How to make time to contribute and mentor How to overcome impostor syndrome and making a welcoming community atmosphere  Throughout the talk, I’ll emphasize several themes.   First: open source contributing can be hard.  Whether you’re a newcomer struggling to install a project or a maintainer who doesn’t know what to say when someone asks how they can help, it’s not your fault, and you’re not alone.  We can work together to make it easier. Second: open source is full of implicit knowledge that needs to be made explicit.  That may mean documenting your toolchain, telling a maintainer what skills you’d like to work on, or setting expectations on how much time you have to work with someone.  In open source, there’s seldom too much information. Finally: every contribution has value.  Newcomers can contribute in meaningful ways from the moment they join a project, though perhaps not always in the ways you imagined.  Let’s encourage every kind of contribution and help ourselves become a bigger, more diverse, and more vibrant community!	Shauna Gordon-McKeon	Community	Open source can be fun and rewarding, but it can also be intimidating.  This talk addresses some of the biggest technical and psychological barriers to contributing, from the perspective of both the newcomers who want to overcome them and the maintainers who want to remove them.	Novice	Open Source for Newcomers and the People Who Want to Welcome Them	Saturday	2015-04-11 12:10:00	2015-04-11 12:55:00
In three hours the instructor will demonstrate and explain 500 Python expressions, grouped by topic, evaluated at the interactive Python prompt.  After each demonstration students will experiment with another 500 expressions provided by the instructor to solidify their understanding of the topic.  Each pairing of demonstration and experimentation lasts less than 15 minutes. Special attention is given to variables (names, namespaces, and objects) because many programmers new to Python assume they understand how they work based on experience in other languages, but later get tripped up by those incorrect assumptions.  Lists and dictionaries, two of Python's workhorse data structures, also receive a lot of attention. Examples of complete Python programs are given only brief treatment near the end, because we assume students already know how and why to write programs.	Stuart Williams	Python Core (language, stdlib, etc.)	A very fast introduction to Python for software developers with experience in other languages.  Instead of a traditional top-down presentation of Python's features, syntax, and semantics, students are immersed in the language bottom-up with hundreds of small examples using the interactive interpreter to quickly gain familiarity with most of the core language features.	Novice	Python by Immersion	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
This tutorial will proceed through each of Django's major components in order, finishing with the administrative interface as an example of how all those components can be tired together. We'll begin with a deep dive into the Django ORM; this will work from the bottom up, showing how Django turns a simple ORM method call into a database query and a set of results. Starting from the level of the database driver, we'll come back up the chain through the Query and QuerySet classes back into the everyday realm of Manager and Model, noting points of flexibility/customization along the way, and useful common patterns and advice for use in real applications. Next we'll turn to the forms library, covering the implementation from Form and Field down into Widget and the full validation process, including all of the customization hooks, before looking at ModelForm and direct model integration and easy methods for generating dynamic custom forms on the fly in application code. From there we'll look at the template language, inside and out, covering all the details of how templates are parsed, compiled and rendered, and a full explanation of how template tags work and of patterns for writing custom tags. Next up is Django's request/response processing pipeline, covering the handler behavior, request and response objects, the middleware system and how Django's URL resolution works and gets to the actual view to call. Following up on that we'll take a look at just what a Django view is, starting with function-based views and then working toward an understanding of class-based views as exemplified by Django's built-in generic views. Finally we'll put it all together with a look at the Django administrative interface, seeing how all the components work together and how the AdminSite and ModelAdmin classes actually work and can be customized.	James Bennett	Web Frameworks	This is a tutorial that goes beyond most tutorials; it's meant for developers who already know a bit about Django and want to really understand the inner guts of the framework. This tutorial will *not* involve writing code or apps; rather, it'll be a deep tour of the workings and APIs of Django itself, across all the bundled components and at all levels of the stack.	Intermediate	Django in Depth	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
Python is quickly becoming the go-to language for data analysis. However, there are so many tools out there that it can be difficult to figure out which ones are useful. In this workshop, I’ll give you an in-depth look at some of the best tools for data wrangling, machine learning, and data visualization. You’ll learn strategies for working with data, how to structure a data analysis workflow, and which tools are appropriate for handling different kinds of data. You’ll leave with a good understanding of different data analysis techniques in Python. Using Pandas, scikit-learn, and matplotlib, we’ll work through a data analysis workflow from start to finish, and we’ll cover the following data analysis problems:  Data preprocessing and data wrangling with Pandas Using scikit-learn for machine learning Visualizing our results with matplotlib  Students should have an intermediate knowledge of Python, including the ability to write functions. Knowing how to use IPython Notebook will also be helpful, since the materials will be in that format. Having all of the materials installed prior to the tutorial is necessary, as I'll only spend a few minutes covering installation, though I'll present several options for participating in the tutorial. These packages are most easily installed through a distribution like Anaconda or Enthought Canopy.	Sarah Guido	Python Libraries	Python is quickly becoming the go-to language for data analysis. However, it can be difficult to figure out which tools are good to use. In this workshop, we’ll work through in-depth examples of tools for data wrangling, machine learning, and data visualization. I’ll show you how to work through a data analysis workflow, and how to deal with different kinds of data.	Intermediate	Hands-on Data Analysis with Python	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
Do you have an API?  Do you accept input from users? Do you accept it in XML? What about YAML? Or maybe JSON? How safe are you? Are you sure? It’s not in the OWASP Top 10, but you don’t have to look far to hear stories of security vulnerabilities involving deserialization of user input. Why do they keep happening? In this talk I’ll go over what the threat is, how you are making yourself vulnerable and how to mitigate the problem. I’ll cover the features (not bugs, features) of formats like XML, YAML, and JSON that make them surprisingly dangerous, and how to protect your code from them. My examples are in Python but are also applicable to other languages and frameworks. Because here’s the thing: If you are using, say, a compliant, properly implemented XML parser to parse your XML, you are NOT safe. Possibly quite the opposite.	Tom Eastman	Security	It’s not in the OWASP Top 10, but you don’t have to look far to hear stories of security vulnerabilities involving deserialization of user input. In this talk I’ll go over what the threat is and how you might be making yourself vulnerable. I’ll cover the features (not bugs: features) of XML, YAML, and JSON that make them surprisingly dangerous, and how to protect your code from them.	Intermediate	Serialization formats are not toys	Sunday	2015-04-12 13:50:00	2015-04-12 14:20:00
"""Neural Nets for Newbies"" is geared to providing clarity on what neural networks are and how to apply them to certain problems. Neural network algorithms have a wide range of applications that handle complex and tough to model data sets.  Example real world applications include classifying galaxies or stars in long range astrophotography, nuanced photo search tools (e.g. find all images that include a type of plant or classify a person in a photo), and voice recognition in customer service and phones.  Neural network modeling is an approach to provide more depth in the way software and hardware applications utilize information. This talk is targeted to anyone who is passionate about finding different ways to define and leverage patterns in data. In the talk, I will cover a high-level history and breakdown what neural networks are and how they are used today. Then I will show you what they look like implemented in Python and discuss validation techniques. Last, I'll touch on existing open source Python packages and what additional resources you can use to learn more. This talk will not make you an expert in neural networks but it will give you an understanding of how to continue studying the space. It will make neural networks more accessible and to increase understanding and acceptance of using them in real world applications."	Melanie Warrick	Other	Neural networks are popular in concept but when faced with real world applications often get dismissed for being too complex or hard to validate. I will break down as simply as possible what neural networks are and real world applications. I’ll take you through example Python code and how to measure performance. Then I’ll outline existing Python packages and where to learn more.	Intermediate	Neural Nets for Newbies	Friday	2015-04-10 16:30:00	2015-04-10 17:00:00
What is an Environment?  Environments are the things that make up your surroundings, both tangible and intangible. The effects that an environment can have on the people in them is profound. Examples of your environment include physical spaces like office layouts. They also include things like stage layouts, where one person is elevated over others giving them power and credibility to speak. The environment is key in shaping that power and credibility. Work environments also include the ability to navigate the job itself. How does one accomplish work, move up in the social structure, etc. The power hierarchy, communication structure, processes, and physical space are all part of the environment for an engineering team. It’s important to understand the environmental factors that affect people’s behavior and ability to be successful at their jobs. Sexism and racism doesn't always manifest as individuals discriminating against individuals. Sometimes it’s a collective group of people (all of us) creating an environment that is better for some than others.  8 Common Problems in Engineering Environments  Onboarding/Training  Currently rely on existing social structures     The first contact a person has with their new team’s environment is the training and on boarding they receive. In tech, training/onboarding is not prioritized and many companies have no on boarding. However, when it comes to people, in the absence of process what ends up happening is that the process relies on the existing social structure. In most tech companies, the existing social structure is the core team that is already there; namely male and often mostly white. This means that the first experience people have with their new environment is inadvertently biased towards people like the existing team in companies that don’t have thoughtful integration and training for new engineers.   Benefits  Parental leave Sick days Vacation Bathroom supplies     Benefits is not a difficult problem to solve although it requires some thought. Make your benefits count and go for the simple wins. Understanding that not all of your employees have the same amount of responsibility outside the company is important; some people have a disproportionate share of the home responsibility. Using young, single people as the baseline for work expectation will alienate people with children, especially those who do most of the childcare.   Safety  Work hours Transportation Safety at conferences      Safety is pretty basic and pretty important. It bleeds into a lot of aspects of work life. A common one is safety getting to and from work; if you expect employees to work late and travel home in the dark, it’s important to remember that safety is going to be a bigger concern for some employees vs. Others. Have transportation plans ready for people working late or people at conferences and events. Otherwise, setup a culture that encourages people to go home while it’s still light out.  There’s the other major issue of safety from other coworkers. We saw with the Tindr lawsuit that safety from coworkers is not a guarantee for many people. This is another area to have a plan and to have process about what to do if one coworker is harassing another. A plan that doesn’t have anything to do with placing blame but that allows any employee to get distance or space from another employee professionally.   Promotions  men promoted based on potential, women (and likely minorities) promoted based on accomplishments http://www.mckinsey.com/client_service/organization/latest_thinking/unlocking_the_full_potential http://www.forbes.com/sites/susanadams/2013/03/04/10-things-sheryl-sandberg-gets-exactly-right-in-lean-in/ http://www.mckinsey.com/careers/women/~/media/Reports/Women/2012%20WSJ%20Women%20in%20the%20Economy%20white%20paper%20FINAL.ashx      By not recognizing subconscious differences in how we promote different groups of people, we create small gaps that grow over time. If women and other minorities have to accomplish a task to be promoted but men simply have to convince others that they could potentially do the task, then you create a small gap that grows over time.   Power structures  Flirting culture   Communication (argument vs. Discussion based culture, using emotions as weapons, gendered-loaded insults, lack of communication channels)  Argument vs. Discussion culture Lack of communication channels      There are two major environmental factors that hurt communication for a lot of people. The first is the argument vs. Discussion based culture. Allowing engineers to argue and creating an argument culture puts an emphasis on the idea of ‘winning’ a conversation. If there is an idea of winning multiple things come out of that environment. Size and aggression will be used as tactics to win. Undermining another person’s point will be used to win. And finally, if something can be won then someone will cheat (that’s why we have refs in sports) and it can encourage unethical behavior like lying or inventing information to win. A discussion based culture is a culture where the emphasis is on finding a shared truth. Because the goal is to collectively come to the best conclusion possible, all viewpoints should be included and acknowledged and points are not given for stomping on other ideas. It’s a seemingly small but critical shift in the way decisions are made and communicated. The second environmental factor that hurts people is having a lack of communication channels. There should be a lot of ways for someone to easily give feedback about the company, processes, organization, or their coworkers that is private and low overhead. Forcing employees to schedule meetings with busy bosses and founders and putting the responsibility on the person with less power to bring forward criticism or bad news will diminish the amount of feedback given.   Process      There’s no such thing as a structure or process not existing for people. In the absence of structure and process, people create it or fall back on unspoken existing structures and processes. A common fallacy of tech companies is in thinking that process is bad (usually because they experienced bad process) and that removing process will fix the problem. Instead, it makes it difficult for people to effectively get things done. Worse, it can inadvertently give certain people will more domain knowledge and power that can never be shared with others. Having no process can also allow people with more power to change the process at any time to fit their needs, but does not allow those with lesser power to do the same. The goal is not no process, the goal is good process.   Empathy -  Weighing people’s emotional problems and experiences more because you understand them.     If people only solve problems that they themselves have experienced, then you get an environment and culture that is tailored to the original core team. Men will never experience gender issues and white people will never experience racial issues, so if white men are the status quo then these problems will not be solved for others in a company without empathy. Empathy involves listening, believing others stories, and understanding them through other people’s experience. It’s common to hear people say we do things this way because in the past I had an experience where we did things another way and it didn’t work, so I learned from it. Empathy is the tool that’s necessary in order to learn from other people’s experiences as well as your own. 	Kate Heddleston	Community	This talk focuses on how engineering team environments can impact employee behavior, and how environmental factors can prohibit diversity at tech companies. I will talk about some of the key problems that exist in current engineering environments and how they can be fixed.	Novice	How our engineering environments are killing diversity (and how we can fix it).	Saturday	2015-04-11 10:50:00	2015-04-11 11:20:00
There are currently three popular approaches to Python concurrency: threads, event loops, and coroutines. Each is shrouded by various degrees of mystery and peril.  In this talk, all three approaches will be deconstructed in a epic ground-up live coding battle. The core topics to be covered include:  Introduction to concurrency with threads. How an event loop works How coroutine-based concurrency works The effect of the GIL The problem with blocking (and workarounds) Coordination with process pools and worker tasks. 	David Beazley	Python Core (language, stdlib, etc.)	There are currently three popular approaches to Python concurrency: threads, event loops, and coroutines. Each is shrouded by various degrees of mystery and peril.  In this talk, all three approaches will be deconstructed and explained in a epic ground-up live coding battle.	Intermediate	Python Concurrency From the Ground Up: LIVE!	Friday	2015-04-10 15:15:00	2015-04-10 16:00:00
Low level operating system functions such as memory management, shared memory, and how the linux kernel keeps track of process information can seem intimidating to high level Python application developers. This talk will provide a gentle, high level overview of how memory works, and introduce some tools, scriptable in Python, to introspect and play with system memory. This talk will demonstrate that such a tool can be easily used to search process memory and kernel memory for interesting patterns and data.	Ying Li	Security	Gumshoes, the rogue program `san_diego.py` is threatening to cause havok!  What is it doing to hide itself?  What kind of things is it doing?  Who might it be communicating with?  RAM is a big place - how can we even find it, much less any of this information? Stay tuned and find out!	Intermediate	"Where in your RAM is ""python san_diego.py""?"	Sunday	2015-04-12 13:10:00	2015-04-12 13:40:00
As the author of many applications and libraries in Erlang and Python I often switch from one to the other during the day. The usage of Erlang definitely changed the way I am coding in Python.  This talk will cover some techniques that are used in Erlang and other functional programming languages and how they can be used to solve problems in more performant, robust and/or concise ways than the standard practices in Python. It will also discuss some possible changes to Python and how such changes could improve its usage by the community.	Benoit Chesneau	Best Practices & Patterns	What can we learn from Erlang for building reliable high concurrency services? This talk will shows some techniques used in Erlang and how they can be used to solve problems in a more efficient way in Python. It will also discuss how Python could evolve accordingly.	Intermediate	What Python can learn from Erlang?	Friday	2015-04-10 13:55:00	2015-04-10 14:25:00
Wheels are the new standard of python distribution and are intended to replace eggs. Support is offered in pip >= 1.4 and setuptools >= 0.8. The wheel format is now the recommended way to ship Python packages on PyPI. Wheels make it possible to very quickly install Python packages on all supported platforms. Packages with compiled extensions can be packaged as platform specific wheels (e.g. 32 bit Windows) so that users do not need a compiler or any other developer tool to pip install them. As part as my involvement as release manager for the scikit-learn project I have spent time and effort to setup an automated CI infrastructure that generates and tests wheel packages for all our supported platforms (Windows, OSX and Linux). This setup makes it possible to support all recent Python versions (2.6+ and 3.3+), both on 32 bit and 64 bit architectures. The goal of this talk is to share the experience and tools I used or developed along this journey. In particular this talk will cover:   how to configure Travis CI to build and test wheel packages for Linux and OSX,   how to configure AppVeyor CI to build and test wheel packages for Windows,   how to embed third party dynamic libraries (.dylib or .dll) in a wheel   package on OSX and Windows to make it independent of non-Python dependencies,   how to setup 32 bit and 64 bit C/C++ and fortran compilers under Windows,   how to maintain a project specific wheelhouse using a public cloud container   such as Amazon S3, Rackspace Cloud Files, Microsoft Azure Blobs  or Google Storage.   how to automate PyPI releases to upload the artifacts generated by CI workers  for a specific tag of your project.   Hopefully by the end of this talk you will have all the necessary pointers and tools to help the Python community build wheel packages for all the projects and all the platforms.	Olivier Grisel	Testing	"Practical guide to build and test wheel packages for all platforms using free
Continuous Integration services such as Travis CI (Linux and OSX) and AppVeyor
(Windows)."	Intermediate	Build and test wheel packages on Linux, OSX & Windows	Saturday	2015-04-11 14:35:00	2015-04-11 15:05:00
"Continuous Deployment is the idea of changes to software being released at extremely frequent intervals as opposed to on a release timetable, and has become a popular method of deploying, in particular, hosted web applications. For many developers and operations professionals, the idea of continuous deployment is not just an end goal, but a process -- it's a continuum.   At one end you start with manual deployment, running commands on boxes.  Then you automate that.  Then you might get a release down to one click to deploy everything, but different manual steps for quality assurance, and those ""turn your keys all at once"" moments that involve several guys locked in a server room on a Saturday night, just in case anything goes wrong.   And something always does. Getting there to Continuous Deployment all the way is great, but getting there even part of the way (and implementing some of the concepts) can yield great improvements in one's day to day job of dealing with software releases.  Along the way, you'll learn about using automation at maximum efficiency to make sure things don't go wrong, and when they do, that you can recover painlessly. This requires many things - an automated development environment that resembles production, a continuous integration system (like Jenkins), a stage environment that even more closely resembles production, integration tests running against this stage environment, and a production environment -- all connected together in sane ways. Combining them together, it's possible to have software decide when to ship code, not humans. In this talk, we'll show you how, giving specific examples of how some major companies got to exactly the place you are going. One of the tools we'll show off is Ansible, a powerful python-powered automation tool, which is one of the top 6 python projects on GitHub in terms of forks today (out of hundreds of thousands of projects).  Ansible's really popular in DevOps circles, due to it's agent-less nature and very large toolbox of included modules.   While it serves many other needs, it was also written specifically for the purpose of enabling zero-downtime rolling updates of infrastructure. We'll show how Ansible can interact with monitoring systems and load balancers to orchestrate updates of complex multi-tier environments, that happen while you sleep, allowing you more time to spend on the coding and IT tasks you want to spend time on, rather than repeating the same manual steps each time you deploy your software. No matter what automation tools you use or whether you adopt a C.D. workflow fully, the lessons learned on the path to continuous deployment will change the way you build, test, and release software for the better."	James Cammarata	Systems Administration	"Continuos Deployment is the act of deploying software constantly.  The idea is if ""release early, release often"" is good, releasing very often is better.  It's not trivial.   Automation is part of the battle, and testing is another.   Learn to use tools like Jenkins and Ansible to move from deploying software once a month to 15 times every hour, and why you'll want to."	Novice	Achieving Continuous Delivery: An Automation Story	Saturday	2015-04-11 13:40:00	2015-04-11 14:25:00
Every wanted to get your feet wet in 3D graphics and animation? Well, you're in luck! This hands-on workshop is a beginner's introduction using Blender and the Blender API. No 3D experience necessary. We'll start off with a quick intro on basic computer graphics (like how 3D models are represented) and then dive into making your own models and scenes. After getting comfortable with the Blender UI, we'll tackle writing scripts to programmatically manipulate everything, from models to lights. You'll learn the quirks of the Blender API, write your very own Blender add-on, and maybe even contribute back to the Blender community. Please bring a mouse with a scroll wheel.	Jenny Cheng	Other	Blender is an amazing open source graphics suite that lets you create animations, edit videos, and much more! It includes a Python API so you can script model creation and animation. Come get started with Blender and the Blender API. You'll learn the basics of 3D modeling and animation, get a guided tour of Blender's features, and write your very own Blender add-on!	Intermediate	Intro to 3D Graphics with Blender and the Blender API	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
"Supervisor is a popular Python application that lets you control and monitor process state on UNIX-like systems. We'll talk about Supervisor's history and its most basic usage, including how to start and stop programs using supervisor and its most basic configuration.  We'll show its RPC API, which allows you to automate supervisor-related tasks.  We'll describe the concept of ""event listeners"" which are programs that receive messages from supervisor when some state has changed, and which can send email or other types of messages, and start, restart, or stop processes.  We'll show how real-world supervisor deployments might go, including how to use the Supervisor installation that's already on your operating system as well as using supervisord inside a Docker container.  Finally, we'll describe what's coming up in Supervisor's future."	Chris McDonough	Systems Administration	Supervisor is a popular Python application that lets you control and monitor process state on UNIX-like systems.  This talk describes what it is, and how to use it effectively to make your application deployments better.	Novice	Using Supervisor For Fun And Profit	Friday	2015-04-10 17:10:00	2015-04-10 17:40:00
"Until recently, the only good option for real-time stream processing in Python was to build your own home-grown solution atop worker-and-queue frameworks like rq or celery. Though these projects are good for distributing workload across Python processes and machines, they do not have built-in mechanisms for message reliability, fault tolerance, or multi-machine cluster management. A new open source project that was developed in the last year and has recently hit a major 1.0 milestone, streamparse, finally makes working with real-time data streams easy for Pythonistas. If you have ever wondered how to process tens of thousands of data tuples per second with Python using long-lived processes -- while maintaining fast throughput, high availability, and low latency -- this talk will give you an overview and deep dive. Detailed Talk Overview What is Storm? Apache Storm is a battle-tested stream processing framework that is already used in production by the likes of Twitter, Spotify, and Wikipedia. Storm has been shown to handle 1,000,000 tuples per second per node in benchmarks (reported by Nathan Marz, author of ""Big Data"" by Manning Press). It has also been shown to scale up to 1,200 nodes across a computation cluster (reported by Twitter). In other words, it is good stuff! Before streamparse, using Storm with Python was a bit painful. Fortunately, streamparse makes using Storm easy and Pythonic, in the same way that mrjob made using Hadoop easy and Pythonic. streamparse components streamparse has four major components:  A command-line tool, sparse, that makes creating Python projects that will work with Storm very easy. A Python module, streamparse, that implements Storm's multi-lang protocol; we call this the IPC (inter-process communication) layer. Extensions for Fabric that allow you to manage a remote cluster of Storm machines, complete with Python dependency management. A thin Java interop layer written in Clojure and accessed with lein that makes it possible for you to manage a Storm cluster and compile Storm topologies from the command line; the Java bits are hidden from the streamparse user so they can work in pure Python.  These will be covered in the talk. Real-world stream processing This talk will also provide an overview of stream processing challenges, and put this in the context of streamparse's (and Storm's) internal architecture. Attendees will be able to use this knowledge to quickly build their own Python-on-Storm topologies, for example implementing a scalable ""real-time word counter topology"" in Python using only a few keystrokes. The talk will conclude by showing how we currently use streamparse, Storm, and Kafka in production to process billions of page views per month of analytics data with sub-second latencies."	Andrew Montalenti	Python Libraries	Real-time streams are everywhere, but does Python have a good way of processing them? Until recently, there were no good options. A new open source project, streamparse, makes working with real-time data streams easy for Pythonistas. If you have ever wondered how to process 10,000 data tuples per second with Python -- while maintaining high availability and low latency -- this talk is for you.	Intermediate	streamparse: real-time streams with Python and Apache Storm	Sunday	2015-04-12 13:10:00	2015-04-12 13:40:00
Test-driven development is a process for writing software that can be safely changed by fallible human beings. Change is inevitable as bugs are found, requirements change and dependencies (operating system, libraries, language) change from under you. Unfortunately as programmers we can only keep so much information in our memory at any given time, not to mention our tendency to make mistakes of every sort. The combination is problematic:  How do we know our software does what we think it does? How do we change our software without breaking existing functionality?  In this talk you'll learn the process of test-driven development (TDD). In TDD the automated tests that will validate the code's correctness are written before the actual code is written. Since the tests will fail before the code is written and pass when it is done we can be sure the code is correct. Since all code has tests we can notice when changes to the code break existing functionality. Writing tests before code may seem confusing or difficult but as you will see it's actually fairly simple to do. The talk will break down the process into clear detailed steps, allowing you to start using TDD on your software projects immediately.	Itamar Turner-Trauring	Testing	Software is maintained by humans with limited memory and an unfortunate tendency to make mistakes. Test-driven development (TDD) can help you work around these design flaws by providing a permanent, automated specification for your code. Learn how to implement TDD when bug fixing and implementing new features and how this process will ensure your code is correct both now and in the future.	Intermediate	A Beginner's Guide to Test-driven Development	Saturday	2015-04-11 12:10:00	2015-04-11 12:55:00
PyPy.js is an experiment in building a fast, compliant, in-browser python interpreter. By compiling the PyPy interpreter into javascript, and retargeting its JIT compiler to emit asmjs code at runtime, it is possible to run python code in the browser at speeds competitive with a native python environment. This talk will demonstrate the combination of technologies that make such a thing possible, the results that have been achieved so far, and the challenges that still remain when trying to take python onto javascript's home turf. We'll cover: an overview of PyPy and why it's a good fit for this type of project; an introduction to asmjs and the rise of javascript as a compile target; what it looks like when you smoosh these two technologies together; a comparison with other approaches such as brython and PythonJS; and some concrete suggestions for how the result might be useful in practice.	Ryan Kelly	Other	PyPy.js is an experiment in building a fast and compliant in-browser python interpreter, by compiling PyPy into javascript and retargeting its JIT to emit javascript code at runtime. This talk will demonstrate the combination of technologies that make such a thing possible, the results achieved so far, and the challenges that still remain when taking python onto javascript's home turf.	Intermediate	PyPy.js: What? How? Why?	Friday	2015-04-10 11:30:00	2015-04-10 12:00:00
"Introduction We start by motivating the running example I'll be using throughout this talk to illustrate the techniques: making a ""linguistic"" street map of Singapore. Why make this map? Why is there so much linguistic diversity among Singapore street names in the first place? I'll answer the latter question with a 2-minute history of Singapore presented via maps. Building a baseline classifier with scikit-learn Next we'll very rapidly go through the steps of building a baseline classifier with scikit-learn: this is basically the contents of the ""Working with Text Data"" tutorial. We'll do data wrangling with GeoPandas, establish a classification schema, build character n-gram features, select a classifier, perform the classification, and evaluate the baseline result. Adding custom feature Pipelines We now look at ways of improving the classifier over the baseline. I'll show how to add custom features beyond those included in scikit-learn, how to build Pipelines for those features, and how to use FeatureUnion to glue them together. Tuning hyperparameters with GridSearchCV() We then look at how to tune hyperparameters using GridSearchCV(). We'll discuss what happens under the hood when you use GridSearchCV(), and how to choose which hyperparameters to experiment with, focusing on Linear SVC as an example classifier. Making the map I'll outline the steps needed to go from the classification results to a whole map using OpenStreetMap data, with the heavy lifting largely provided by Mapnik, a C++ tool for developing mapping applications with Python bindings. It's actually easier than you might think! Conclusion We'll recap what we've done and review which method of improving the baseline classifier worked best: more data, adding features, hyperparameter tuning, or swapping out classifiers?"	Michelle Fullwood	Python Libraries	Have you built a classifier in scikit-learn with out-of-the-box features, been disappointed with the results, and wanted to know where to go next? This talk shows how to add your own feature Pipelines and how to tune hyperparameters using GridSearchCV. We'll apply this to the problem of classifying streetnames in Singapore by linguistic origin, and turn the results into a colour-coded street map.	Intermediate	Grids, Streets and Pipelines: Building a linguistic street map with scikit-learn	Friday	2015-04-10 14:35:00	2015-04-10 15:05:00
Why does no one talk about the bytearray? With what great hopes was it added to the Python language? It might nearly be suspected of violating “there should be one obvious way to do it” by supporting a whole parallel ecosystem of shadowy techniques for parsing data and accelerating I/O while dodging normal Python strings. What do these techniques really accomplish? This talk will make practical and honest comparisons about the damage that bytearray techniques can do to your code as you contort it into ever more interesting shapes to try to minimize the number of times you copy data. After all, you reason, modern processors are usually starved for more data from RAM, and any technique that reduces the number of times string operations copy data into new regions of memory has got to be a win — right? Not nearly as often as you think. Through benchmarks and careful observation, we will learn when to identify those rare situations where sheer data copying is genuinely a limiting factor in your application’s performance — and how, in those situations, to pull out the bytearray and let it roll. Its effect in PyPy and Cython will be compared to our mental model of how it improves performance in vanilla C Python.	Brandon Rhodes	Python Core (language, stdlib, etc.)	Python string operations are profligate in their use of memory — the steps necessary to parse an HTTP request often make four or five copies of every incoming byte. But does it matter? This talk explores the “bytearray”, shows how its proper use dramatically reduces copying, but then uses metrics and visualizations to determine whether any increase in performance is worth the added complexity.	Intermediate	Oh, Come On. Who Needs Bytearrays?	Saturday	2015-04-11 16:15:00	2015-04-11 17:00:00
SaltStack (Salt for short) is a system management platform written in Python.  In this session, we will start from the beginning.  We will learn how to install salt and get it set up on a system.  We will learn how to run commands from our Salt “Master” to our Salt “Minions”.  We will also delve a little bit into the State system in Salt, which is Salt’s take on configuration management. This talk will give you the tools to get started managing your systems with Salt.  You’ll be able to immediately begin using it to make your job of managing your servers easier. Assuming we still have time, we’ll look a little deeper into what’s going on underneath the commands we are sending, and discover just how easy it is to extend SaltStack for our specific needs, via custom execution modules and state modules. This talk will be useful for anyone who administrates systems.  This includes the devops community, system administrators, and even people who want to use SaltStack for their personal servers.  It will also be a great introduction to one of the biggest Python projects on Github, for those looking for a great project to which they can contribute.	Colton Myers	Systems Administration	Are you still using SSH to manage your servers? Deploying code manually with rsync? There’s a better way. SaltStack is one of the latest and greatest tools for system management. Once you have a foundation of lightning-fast remote execution, you can build anything on top of it. Plus, it’s written in Python, and easy to extend!	Novice	Managing Your Infrastructure with SaltStack	Saturday	2015-04-11 17:10:00	2015-04-11 17:40:00
What with the proliferation of device/applications for remotely controlling everything from your lights to your coffee maker, and with the release of HomeKit in iOS 8, it's clear that companies big and small are getting into the home-automation game. But why just not do it yourself? In this talk, I'll show you everything you need to know to turn your boring window-unit air conditioner into a wifi-enabled, remotely controllable smart-thermostat. With a couple components, a Raspberry Pi, and some handy Python libraries, you'll not only have the tools to make yourself a Smart AC, you'll be able to execute other cool home-automation projects you've dreamed up. (I'm thinking an alarm for the morning that starts my coffee pot.) You do not need to have any previous experience with Raspberry Pi or hardware projects! I'll go over the simple circuits you'll make, tips for debugging hardware, and the libraries you'll need. I’ll also cover how to set up a simple flask server that will allow you to communicate with your device from your web browser. I'll wrap up the talk with pointers to some excellent resources and a quick video demo of my Smart AC in action.	Miriam Lauter	Other	Looking for a fun, useful Raspberry Pi project? Want to connect your household appliances to the internet? Come learn how to build your own 'smart' air conditioner using a Raspberry Pi, a bit of hardware, and, of course, Python. Plus, you can save energy and never have to come home to a sweltering bedroom again.	Novice	Make your own Smart Air Conditioner	Friday	2015-04-10 14:35:00	2015-04-10 15:05:00
You might think of the Linux kernel as something that only kernel developers need to know about. Not so! It turns out that understanding some basics about kernels and systems programming makes you a better developer, and you can use this knowledge when debugging your normal everyday Python programs. We’ll talk about how to use strace, ltrace, /proc, and friends to debug your servers and your misbehaving programs. A few specific tricks we’ll cover:  how to recover files with /proc (and other tricks) using strace to understand programs without reading their source code easily hunting down which log file a program is writing to and what commands it’s executing  You’ll come away with a new toolset for debugging your programs that works in any programming language. This talk will be focused on Linux tools, with some references to their OS X counterparts.	Julia Evans	Other	You might think of the Linux kernel as something that only kernel developers need to know about. Not so! It turns out that understanding some basics about kernels and systems programming makes you a better developer, and you can use this knowledge when debugging your normal everyday Python programs.	Novice	Systems programming as a swiss army knife	Saturday	2015-04-11 10:50:00	2015-04-11 11:20:00
This talk is part coding, part lessons learned. We will do a hands on walk through of a couple of web scrapers. During the walk through, we will stop periodically to discuss to how the web works and how web pages are constructed. These stopping points will help break down how to get the content that we are looking for. Besides looking at how websites are put together, we will also discuss the ethics of scraping. What is legal? How can you be a friendly scraper, so that the administrator of the website you are scraping won’t try to shut you down? Lastly, we will cover some projects where folks used scraping techniques and the projects that came out of those. We will also share some datasets that could be scraped for inspiration, and how to get started with those examples.	Jackie Kazil,Sisi Wei	Python Libraries	Sometimes data does not come in a format that we would like it in, and we need to other mechanisms to collect data. This tutorial taught, from the perspective of a data journalist and a data scientist, who will give you an overview of use cases of how some folks have used web scraping for data collection, how to get started, where to find data, and what are the ethics behind it.	Novice	How to start web scraping	Thursday	2015-04-09 13:20:00	2015-04-09 16:40:00
"Four years after the Arab Spring and two years after the Snowden revelations about NSA spying, it appears that little has changed. We'll answer the question ""what now?"" by remember the ad-hoc activist cluster Telecomix. Called ""Tech Support for the Arab Spring"", Telecomix helped keep Egypt & Syria online, using everything from encryption to dialup modems and fax machines. We helped to catch a US company selling surveillance to dictators, defend journalists against Chicago cops and rally thousands to the streets of Europe against the ACTA copyright treaty. We spend more time hanging out on IRC than is technically healthy. This talk will reflect on lessons learned during last three years of hands-on ""hacktivism"" and explore similarities with the free software community. It's a follow-up to a 2011 Pycon lightning talk given shortly after the Tahrir Square protests."	Pete Fein	Community	Four years after the Arab Spring & 2 years after Snowden, little has changed. What now? This talk will remember Telecomix, an ad-hoc activist cluster that supported free communication around the world. Stories of humans and machines, reflection on 3 years of hacktivism & exploration of similarities to the free software community. It follows a 2011 Pycon lightning talk given after Tahrir Square.	Novice	Free Software, Free People	Sunday	2015-04-12 13:10:00	2015-04-12 13:40:00
"How to not read code This talk will cover three strategies for exploring codebases that go beyond ""just read the code!"". I'll outline each strategy, provide tools that are useful for each one, and give a short demonstration of answering a real question using that strategy.  Code as nature & the programmer as naturalist (with inspect/cinspect) Science! Hypothesis-driven exploration (with timeit) Code as architecture: Guided tours (with ack) "	Allison Kaptur	Python Core (language, stdlib, etc.)	"Have you started to read the source code of CPython but not gotten as far as you wanted? Maybe you want to understand more about CPython but don't know where to begin. I'll present a number of strategies for getting more familiar with Python under the hood that go beyond ""just read it!"" This talk isn't about contributing - it's about getting into the code base and discovering interesting things."	Novice	Exploring is never boring: understanding CPython without reading the code	Saturday	2015-04-11 14:35:00	2015-04-11 15:05:00
"The world is full of badly designed and difficult to use Web APIs. The REST architecture tries to make APIs better by defining a set of guiding principles that give APIs a predictable behavior modeled after the familiar HTTP protocol of World Wide Web fame. Unfortunately some of the REST principles are hard to grasp, so many APIs implement them incorrectly. For example, developers used to build APIs using other paradigms may find the focus on resources and the state transitions unconventional. Also, some of the REST principles go against well established practices for building traditional Web applications, so developers that transition to APIs usually apply techniques they learned before, such as those involving user sessions or cookies, without knowing or understanding why those are frowned upon in APIs. Now don't get me wrong, I have built bad APIs as much as the next person, so in this session I do not plan to point fingers at anyone. My intention is to explain the REST principles as I understand them and in plain English, so that the next time you design an API you have all the elements to decide if this approach is the right one for your project. I will sort the six principles by their level of complexity and then systematically go through them starting from the easier ones. For each one I will tell you what do you gain if you abide by it, and what do you lose if you don't. I will give special attention to the ""Uniform Interface"" principle, the most complex of the set, which I will cover as four sub-topics. To conclude, I will do a live demonstration, where I will play the part of an API client and show you how to access an example API written in Python with the Flask microframework. Starting with the API documentation as a guide I will show you how to work with this example API using a command line HTTP client."	Miguel Grinberg	Best Practices & Patterns	Writing a fully complaint REST API is hard, so hard it is too common for APIs to violate one or more of the REST architectural principles. In this talk I will describe the six REST principles, and I will tell you what happens if you don't follow them.	Intermediate	Is Your REST API RESTful?	Friday	2015-04-10 16:15:00	2015-04-10 17:00:00
Machine learning is the branch of computer science concerned with the development of algorithms which can be trained by previously-seen data in order to make predictions about future data. It has become an important aspect of work in a variety of applications: from optimization of web searches, to financial forecasts, to studies of the nature of the Universe. This tutorial will explore machine learning with a hands-on introduction to the scikit-learn package.  Beginning from the broad categories of supervised and unsupervised learning problems, we will dive into the fundamental areas of classification, regression, clustering, and dimensionality reduction.  In each section, we will introduce aspects of the Scikit-learn API and explore practical examples of some of the most popular and useful methods from the machine learning literature. The strengths of scikit-learn lie in its uniform and well-document interface, and its efficient implementations of a large number of the most important machine learning algorithms. Those present at this tutorial will gain a basic practical background in machine learning and the use of scikit-learn, and will be well poised to begin applying these tools in many areas, whether for work, for research, for Kaggle-style competitions, or for their own pet projects.	Jake VanderPlas	Science	This tutorial will offer an introduction to the core concepts of machine learning and the Scikit-Learn package. We will introduce the scikit-learn API, and use it to explore the basic categories of machine learning problems and related topics such as feature selection and model validation, and practice applying these tools to real-world data sets.	Intermediate	Machine Learning with Scikit-Learn (I)	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
Introduction Python developers often seem apprehensive about descriptors. This talk aims to remove some of the fear surrounding writing custom descriptors. Definition A descriptor is a class that allows the programmer to define how given attributes are accessed and modified on an object. They define one or more of the methods __get__, __set__, or __del__. This allows the user to specify how attributes are declared and used with a greater deal of precision than a standard attribute declaration on an object. Common Examples Some relatively common examples of descriptors used in Python include decorators such as @property and @classmethod, which serve as a shorthand for relatively simple descriptors. Database Object Relational Mappers (ORMs) that interface with Python, such as used with Django, often take advantage of descriptors to simplify the declaration of attributes and control the data types being stored, which would otherwise be tedious given Python’s duck typing. Ever get a read-only property error? This is often the side effect of a descriptor with a __get__ method defined but no __set__ method defined. Making your own custom descriptors to simplify code With descriptors, Python developers can have greater control of code with less repetition. It is important to avoid circular loops which can occur when getting or setting attributes within the __get__ or__set__ variables within Python. And in case anything goes wrong, the appropriate Exceptions should be used to ease use and allow for debugging.	Laura Rupprecht	Python Core (language, stdlib, etc.)	The Python library uses descriptors frequently, but most developers overlook this feature. This talk will cover what a descriptor is, the current uses in the standard library, and how custom descriptors can be used in a developer’s toolset to eliminate repeated code.	Intermediate	Describing Descriptors	Saturday	2015-04-11 15:15:00	2015-04-11 15:45:00
Please see the outline, which combines the abstract with a detailed approach to how present this talk.	Jim Baker	Python Core (language, stdlib, etc.)	"So how did we get to Jython 2.7 anyway? And what are our future plans?
In this talk, you will get a taste of how Jython works, some new
functionality, and especially how Jython leverages both Python and
Java to provide a very compatible solution."	Experienced	Getting to Jython 2.7 and beyond	Sunday	2015-04-12 14:30:00	2015-04-12 15:00:00
0. Background High-quality free satellite data is available nowadays for simple download from agencies such as NASA, NOAA, ESA or the USGS. Imagery to resolutions of about 15-30m is detailed enough to map regional processes, be they environmental, industrial, or related to catastrophic events. But even coders who use GIS data as a matter of course are not often comfortable generating their own RGB raster maps. On the other hand, students and researchers in geospatial disciplines are often stuck in clumsy GUI-driven software and are unfamiliar with how a general purpose scripting language with excellent library support can help them.  This talk aims to bridge this gap: to give Python coders the enough knowledge of the anatomy of a satellite imagery scene, show researchers the power of Python, and point both to the best libraries to get both groups started on their mapping project. 1. For example, natural hazard mapping with Landsat. Satellite imagery comes in many data file formats, from the straightforward to the frustrating and convoluted. We will spend the bulk of the talk on the easiest format: GeoTIFF, which is essentially a TIFF file with extra tags with information about data types, geographic extent and map projection. Luckily, GeoTIFF is not only the most friendly format for satellite imagery, it is also the one used by US Geological Survey, which distribute images from the Landsat family of earth observing satellites.  Landsat images are not super-high resolution, but good enough to show roads, fields, rivers, industrial installations, forests, and  landscape structures. Their quality is superb. An example is this before/after image of a pond at the Mount Polley mine in BC, Canada, which, in early August, 2014, developed a breach and released toxic wastewater into the surrounding waters.   2. Data details  The scene comes as a zip file or tarball which contains a plain-text metadata file and, depending on the version of the satellite, a varying number of GeoTIFF files with the same footprint. Any three of these are used to make false-color RGB images.  We will use the GDAL library to read the images. This provides access to the data itself appears as Numpy arrays. GDAL makes it easy to relate rater indices to geographic location, while Numpy takes over the task of subsetting and data type conversion. The wrapper classes I have written remove some of the complexity. High-quality maps are generated with Matplotlib's Basemap toolkit, and all code will be available in iPython notebooks.  3. Beyond Landsat A short section at the end of the talk will be devoted to data file formats that are less accessible than GeoTIFF, specifically HDF-EOS (used by NASA) and HDF5 (used among others by NOAA). HDF5 in particular is worth knowing as it is a good choice for storing your own raster data.  It turns out that making raster maps from satellite data is in no way harder than using shapefiles for GIS applications. Both can be combined using the Basmeap and/or the powerful shapely/fiona set of libraries An animation]4 is online, and some code examples can be found in IPython notebooks here and here. 	Chris Waigl	Science	Concerned about urban sprawl, landscape change or ecosystem recovery? Wildfire, drought or flooding? A vast amount of satellite data, collected since the 1970s, is freely available for your next mapping project. I will demonstrate how Python helps to make sense of odd scientific data and metadata formats and produce beautiful visualization and map products.	Novice	Satellite mapping for everyone	Friday	2015-04-10 13:55:00	2015-04-10 14:25:00
"We'll discuss each kind of the most prevalent security flaws at the theoretical level, then using a specially-crafted, deliberately vulnerable app, individuals or pairs will carry out exploits against these flaws, and we'll discuss strategies for mitigating each type of attack in several popular Python frameworks. We'll be using the OWASP Top 10 as our topic roadmap, addressing issues such as:  Injection Attacks Broken Authentication & Session Management Cross-Site Scripting (XSS) Insecure Direct Object References Security Misconfiguration Sensitive Data Exposure Missing Function-Level Access Control Cross-Site Request Forgery (CSRF) Using Components with Known Vulnerabilities Unvalidated Redirects and Forwards  You'll want to set your brain to ""devious"" mode; you'll also need a laptop with Python 2.7 or 3.3 (or a buddy you can pair with). Having pip and virtualenv will be useful too, as will having Git installed to pull down the code we'll be working with. Attendees do not need prior security experience; this tutorial is aimed at intermediate web developers who are interested in gaining hands-on experience with simple forms of the most common attacks. Attendees should have some experience with Python, Javascript, and SQL, and may benefit from at least a passing familiarity with Django (eg, previously attending a Django tutorial or working through the online tutorial)."	Mike Pirnat,David Stanek	Security	The Internet is a dangerous place, filled with evildoers out to attack your code for fun or profit, so it's not enough to just ship your awesome new web app--you have to take the security of your application, your users, and your data seriously. You'll get into the mindset of the bad guys as we discuss, exploit, and mitigate the most common web app security flaws in a controlled environment.	Intermediate	Shiny, Let's Be Bad Guys: Exploiting and Mitigating the Top 10 Web App Vulnerabilities	Wednesday	2015-04-08 09:00:00	2015-04-08 12:20:00
If we assume that more and more of the web will be built in the frontend with tools like AngularJS and Backbone.js, where does Python fit into that ecosystem?  If we love Python (and I do!) we want to position it well as part of that ecosystem. This means, among other things, that we want to best and most robust tools for building REST interfaces on the server side. These tools should be simple to pick up but powerful under the hood.  Today's REST ecosystem in Python is underpowered for the world we're heading into. We'll cover the state of the art in REST, as well as the areas where our tools can do a better job to support us.	Jeff Schenck	Web Frameworks	As frontend web frameworks like AngularJS and Backbone.js take over, is Python on the server destined to be demoted to a basic REST interface? If we embrace our new JavaScript overlords, how do we ensure Python is best positioned for this new world of REST on the server?	Intermediate	The REST Ascendancy	Friday	2015-04-10 17:10:00	2015-04-10 17:40:00
3D printing is a powerful technology that excels at rapid prototyping and producing custom objects. It's easy to get started with 3D printing. All you need is a 3D model and the 3D printer will build it, layer by layer. You can print models on your own 3D printer, or rent one from local hackerspaces, schools, or universities. You can also outsource the printing by using one of the many online services. Ready to 3D print? Let's make some models with Blender! Blender is an open source graphics suite that's great for creating and manipulating 3D models. It also features a rich Python 3 API. We'll explore how to use that API to programmatically create new models for 3D printing. You'll learn how 3D models are represented and how to create and manipulate a model through different API modules. You'll see example applications like 3D printing your own glasses.  The API is not only good for creating models, but also procedurally fixing unprintable models. You'll learn what makes models unprintable, the 3D printing constraints models must obey, and solutions provided by the API. 	Jenny Cheng	Other	3D printing is an awesome manufacturing process that makes physical objects from 3D models. Want to get started with 3D printing? Let's make some models to print! Learn how to create and manipulate 3D models using Python, Blender (an open source graphics suite), and the Blender API. You'll leave this talk with the basics to help you 3D print objects for the real world.	Intermediate	3D Print Anything with the Blender API	Friday	2015-04-10 15:15:00	2015-04-10 15:45:00
Bayesian statistical methods are becoming more common and more important, but there are not many resources to help beginners get started.  People who know Python can use their programming skills to get a head start. I will present simple programs that demonstrate the concepts of Bayesian statistics, and apply them to a range of example problems.  Participants will work hands-on with example code and practice on example problems. Attendees should have at least basic level Python and basic statistics.  If you learned about Bayes’s theorem and probability distributions at some time, that’s enough, even if you don’t remember it! Attendees should bring a laptop with Python and matplotlib.  You can work in any environment; you just need to be able to download a Python program and run it.  I will provide code to help attendees get set up ahead of time.	Allen Downey	Science	An introduction to Bayesian statistics using Python.  Bayesian statistics are usually presented mathematically, but many of the ideas are easier to understand computationally.  People who know Python can get started quickly and use Bayesian analysis to solve real problems.  This tutorial is based on material and case studies from Think Bayes (O’Reilly Media).	Intermediate	Bayesian statistics made simple	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Setting the scene My boss alerted me to an article on a popular site, which claimed to show that my open-source Python client for MongoDB is three times slower than the Javascript client. Anxiety immediately set in: Was this true? Could I improve it? What should I tell my boss? Why profile? A typical program spends almost all its time in a small subset of its code. Optimizing those hotspots is all that matters. This is what a profiler is for: it leads us straight to the functions where we should spend our effort. So I decided to profile the code in the article to see why it was slow. Which profiler? I’ll describe three open-source profilers for Python: cProfile is a fast single-thread profiler included in the Python standard library. GreenletProfiler is my package for profiling Gevent applications. Yappi is a third-party package that can profile multiple threads. I used Yappi for this investigation, since it’s the most featureful. How do we profile and what information do we get? Yappi has configuration options for how it measures time and which functions it profiles. I’ll show you how I configured and ran Yappi, and how I visualized its output in KCacheGrind. How do we use the profiling information? I used KCacheGrind’s different views to narrow the search for hotspots, and calculated upper bounds for what performance enhancements I could achieve. Optimization is like debugging: we form a hypothesis for what changes will yield the best speedups, than perform experiments. This forms a virtuous cycle of benchmarking and improving our code. I’ll relate the shocking conclusion to my investigation of the slow code. How does profiling work? If you’re like me, you can’t sleep if you don’t understand how something works. We’ll briefly explore how cProfile and Yappi hook into the Python interpreter’s guts, and how Yappi employs a clever trick to efficiently profile all running threads.	A. Jesse Jiryu Davis	Python Libraries	Your Python program is too slow, and you need to optimize it. Where do you start? With the right tools, you can optimize your code where it counts. We’ll explore the guts of the Python profiler “Yappi” to understand its features and limitations. We’ll learn how to find the maximum performance wins with minimum effort.	Intermediate	Python Performance Profiling: The Guts And The Glory	Sunday	2015-04-12 13:50:00	2015-04-12 14:20:00
This tutorial is a systematic introduction to descriptors and metaclasses. It covers all relevant information with a focus on practical applications for common tasks. In hand-on sessions you will learn how to write your own descriptors that adapt attribute access to your needs. You will experience how metaclasses can help you to get more insight into a code base. Use cases provide working code that can serve as a basis for your own solutions. You will gain a deeper understanding of more advanced concepts that can help to write better programs. I've been delivering these topics over the last years as a part of an advanced training in open and in-house courses as well as trainings at EuroPython, PyCon PL, PyCon DE and PyCon IE. The material has been continuously refined owing to the participant feedback.	Mike Müller	Python Core (language, stdlib, etc.)	"Descriptors and metaclasses are advanced Python features. While it is
possible to write Python programs without active knowledge of them,
knowing more about them facilitates a deeper understanding of
the language. With examples, you will learn how they work and how to
write your own descriptors and metaclasses. Furthermore, you will understand
when to use and when better not to use them."	Experienced	Descriptors and Metaclasses - Understanding and Using Python's More Advanced Features	Thursday	2015-04-09 09:00:00	2015-04-09 12:20:00
Using examples from real-code, show what really matters to make code readable and maintainable. Learn how to leverage Python's toolset for maximum effect (named tuples, keyword arguments, doctests, decorators, content managers, properties, modules, packages, logging, and exception handlers).  Avoid the hazards associated with a too shallow interpretation of PEP 8 and instead use it to nudge yourself toward consistent, nice-looking, clear code.	Raymond Hettinger	Best Practices & Patterns	Distillation of knowledge gained from a decade of Python consulting, Python training, code reviews, and serving as a core developer.   Learn to avoid some of the hazards of the PEP 8 style guide and learn what really matters for creating beautiful intelligible code.	Intermediate	Beyond PEP 8 -- Best practices for beautiful intelligible code	Friday	2015-04-10 12:10:00	2015-04-10 12:55:00
The goal of static code analysis is to generate useful insights from code without actually executing it. In the talk I will explain how tools for static analysis of Python code work and which challenges we face when analyzing code in such a highly dynamic scripting language. I will give an overview of currently available tools for static analysis and show some of their use cases and limitations. I will then explain how we can make use of publicly available source code and user-provided examples of code errors to improve the quality of our analysis results and learn to detect new types of errors.	Andreas Dewes	Best Practices & Patterns	Static code analysis is an useful tool that can help to detect bugs early in the software development life cycle. I will explain the basics of static analysis and show the challenges we face when analyzing Python code. I will introduce a data-driven approach to code analysis that makes use of public code and example-based learning and show how it can be applied to analyzing Python code.	Intermediate	Learning from other's mistakes: Data-driven analysis of Python code	Saturday	2015-04-11 11:30:00	2015-04-11 12:00:00
In many ways Python is very similar to other programming languages.  However, in a few subtle ways it is quite different, and many software developers new to Python, after their initial successes, hit a plateau and have difficulty getting past it.  Others don't hit or perceive a plateau, but still find some of Python's features a little mysterious or confusing.  This tutorial will help deconstruct some common incorrect assumptions about Python. If in your use of Python you sometimes feel like an outsider, like you're missing the inside jokes, like you have most of the puzzle pieces but they don't quite fit together yet, or like there are parts of Python you don't understand, this may be a good tutorial for you. After completing this tutorial you'll have a deeper understanding of many Python features.  Here are some of the topics we'll cover:   How objects are created and names are assigned to them   Ways to modify a namespace: assignment, import, function definition and call, and class definition and instantiation.  Much of the tutorial is structured around namespaces and ways to change them to help you understand most of the differences between variables in other languages and Python, including   why Python has neither pass-by-value nor pass-by-reference function call semantics,   and why parameters passed to a function can sometimes be changed by it and sometimes cannot.     Iterables, iterators, and the iterator protocol, including how to make class instances iterable   How to use generators to make your code easier to read and understand   Hacking classes after their definition, and creating classes without a class statement, as an exercise to better understand how they work   Bound versus unbound methods, how they're implemented, and interesting things you can do with bound methods   How and why you might want to create or use a partial function   Example use-cases of functions as first-class objects   Unpacking and packing arguments with * and ** on function call and definition  	Stuart Williams	Python Core (language, stdlib, etc.)	This tutorial is for developers who've been using Python for a while and would consider themselves at an intermediate level, but are looking for a deeper understanding of the language.  It focuses on how Python differs from other languages in subtle but important ways that are often confusing, and it demystifies a number of language features that are sometimes misunderstood.	Intermediate	Python Epiphanies	Wednesday	2015-04-08 13:20:00	2015-04-08 16:40:00
